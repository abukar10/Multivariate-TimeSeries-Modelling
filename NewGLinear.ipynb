{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22143,
     "status": "ok",
     "timestamp": 1748774280320,
     "user": {
      "displayName": "amali amali",
      "userId": "15718090331232743656"
     },
     "user_tz": -60
    },
    "id": "AVYOLycMwbiE",
    "outputId": "47b0e2da-0c4e-4a79-fea1-c786b31e4997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1748774283018,
     "user": {
      "displayName": "amali amali",
      "userId": "15718090331232743656"
     },
     "user_tz": -60
    },
    "id": "HyZ0V90vxTn6",
    "outputId": "282bb2e4-b5b1-4235-df99-fbd97e9f31cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/MyProject_QMUL_Final\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/MyProject_QMUL_Final/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1748774286067,
     "user": {
      "displayName": "amali amali",
      "userId": "15718090331232743656"
     },
     "user_tz": -60
    },
    "id": "gYW-Ng7OxE8w",
    "outputId": "c7331737-f163-464b-9d63-4485f8388e09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/MyProject_QMUL_Final\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVUYTGShxcvB"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/t-rizvi/GLinear.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1748774294932,
     "user": {
      "displayName": "amali amali",
      "userId": "15718090331232743656"
     },
     "user_tz": -60
    },
    "id": "N4o-lTEjyI0x",
    "outputId": "95e63d69-d0f7-480d-d537-bc000d655146"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/MyProject_QMUL_Final/GLinear\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/MyProject_QMUL_Final/GLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90,
     "status": "ok",
     "timestamp": 1748774308637,
     "user": {
      "displayName": "amali amali",
      "userId": "15718090331232743656"
     },
     "user_tz": -60
    },
    "id": "WaTzpuGryK04",
    "outputId": "23954e25-0cc4-4546-de86-525bad949474"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_provider  layers\tNewGLinear.ipynb  result.txt\t  utils\n",
      "dataset        LICENSE\tREADME.md\t  run_longExp.py\n",
      "exp\t       logs\trequirements.txt  scripts\n",
      "Extra\t       models\tresults\t\t  test_results\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1748774320351,
     "user": {
      "displayName": "amali amali",
      "userId": "15718090331232743656"
     },
     "user_tz": -60
    },
    "id": "y0IXwE2va6xO",
    "outputId": "68dbaa05-98ca-4e02-bde4-d396fae7d08f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/MyProject_QMUL_Final/GLinear\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/MyProject_QMUL_Final/GLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "collapsed": true,
    "id": "JKUmD5lV3V9O",
    "outputId": "f6218a1a-b563-46b4-d4d3-7fa8ab28b8a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, train_only=False, model_id='ETTh1_336_96', model='GLinear', data='ETTh1', root_path='dataset/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='/spo/NewbornTime/tahir098/SVF/data/Extra/checkpoints/', seq_len=336, label_len=48, pred_len=336, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.01, des='test', loss='mse', lradj='type1', use_amp=False, use_gpu=False, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use CPU\n",
      ">>>>>>>start training : ETTh1_336_96_GLinear_ETTh1_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7969\n",
      "val 2545\n",
      "test 2545\n",
      "\titers: 100, epoch: 1 | loss: 0.7041411\n",
      "\tspeed: 0.0628s/iter; left time: 150.2504s\n",
      "\titers: 200, epoch: 1 | loss: 0.6399285\n",
      "\tspeed: 0.0119s/iter; left time: 27.2189s\n",
      "Epoch: 1 cost time: 3.8075480461120605\n",
      "Epoch: 1, Steps: 249 | Train Loss: 0.7066524 Vali Loss: 1.6713527 Test Loss: 0.6810130\n",
      "Validation loss decreased (inf --> 1.671353).  Saving model ...\n",
      "Updating learning rate to 0.01\n",
      "\titers: 100, epoch: 2 | loss: 0.6743166\n",
      "\tspeed: 0.0323s/iter; left time: 69.2299s\n",
      "\titers: 200, epoch: 2 | loss: 0.6660821\n",
      "\tspeed: 0.0143s/iter; left time: 29.2838s\n",
      "Epoch: 2 cost time: 3.4681811332702637\n",
      "Epoch: 2, Steps: 249 | Train Loss: 0.6880614 Vali Loss: 1.6239773 Test Loss: 0.6825538\n",
      "Validation loss decreased (1.671353 --> 1.623977).  Saving model ...\n",
      "Updating learning rate to 0.005\n",
      "\titers: 100, epoch: 3 | loss: 0.7042074\n",
      "\tspeed: 0.0336s/iter; left time: 63.5134s\n",
      "\titers: 200, epoch: 3 | loss: 0.6852787\n",
      "\tspeed: 0.0123s/iter; left time: 22.0465s\n",
      "Epoch: 3 cost time: 3.2498435974121094\n",
      "Epoch: 3, Steps: 249 | Train Loss: 0.6580593 Vali Loss: 1.6940095 Test Loss: 0.6787634\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0025\n",
      "\titers: 100, epoch: 4 | loss: 0.6081387\n",
      "\tspeed: 0.0334s/iter; left time: 54.8927s\n",
      "\titers: 200, epoch: 4 | loss: 0.6349819\n",
      "\tspeed: 0.0126s/iter; left time: 19.4221s\n",
      "Epoch: 4 cost time: 3.34275484085083\n",
      "Epoch: 4, Steps: 249 | Train Loss: 0.6244526 Vali Loss: 1.6632565 Test Loss: 0.6877252\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.00125\n",
      "\titers: 100, epoch: 5 | loss: 0.6181502\n",
      "\tspeed: 0.0345s/iter; left time: 48.1080s\n",
      "\titers: 200, epoch: 5 | loss: 0.5721111\n",
      "\tspeed: 0.0124s/iter; left time: 16.1070s\n",
      "Epoch: 5 cost time: 3.2771520614624023\n",
      "Epoch: 5, Steps: 249 | Train Loss: 0.6006216 Vali Loss: 1.6467208 Test Loss: 0.6997127\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh1_336_96_GLinear_ETTh1_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2545\n",
      "mse:0.6801467537879944, mae:0.5333603620529175\n",
      "Use CPU\n",
      ">>>>>>>start training : ETTh1_336_96_GLinear_ETTh1_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7969\n",
      "val 2545\n",
      "test 2545\n",
      "\titers: 100, epoch: 1 | loss: 0.7445256\n",
      "\tspeed: 0.0142s/iter; left time: 33.8570s\n",
      "\titers: 200, epoch: 1 | loss: 0.6154284\n",
      "\tspeed: 0.0122s/iter; left time: 27.9250s\n",
      "Epoch: 1 cost time: 3.295023202896118\n",
      "Epoch: 1, Steps: 249 | Train Loss: 0.7172189 Vali Loss: 1.5994463 Test Loss: 0.6743854\n",
      "Validation loss decreased (inf --> 1.599446).  Saving model ...\n",
      "Updating learning rate to 0.01\n",
      "\titers: 100, epoch: 2 | loss: 0.6901826\n",
      "\tspeed: 0.0352s/iter; left time: 75.3766s\n",
      "\titers: 200, epoch: 2 | loss: 0.6271987\n",
      "\tspeed: 0.0123s/iter; left time: 25.0709s\n",
      "Epoch: 2 cost time: 3.2926933765411377\n",
      "Epoch: 2, Steps: 249 | Train Loss: 0.6727735 Vali Loss: 1.6408236 Test Loss: 0.6727263\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.005\n",
      "\titers: 100, epoch: 3 | loss: 0.6081312\n",
      "\tspeed: 0.0351s/iter; left time: 66.4158s\n",
      "\titers: 200, epoch: 3 | loss: 0.6090342\n",
      "\tspeed: 0.0127s/iter; left time: 22.7105s\n",
      "Epoch: 3 cost time: 3.2849063873291016\n",
      "Epoch: 3, Steps: 249 | Train Loss: 0.6401393 Vali Loss: 1.6475270 Test Loss: 0.6707926\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0025\n",
      "\titers: 100, epoch: 4 | loss: 0.5909897\n",
      "\tspeed: 0.0344s/iter; left time: 56.5381s\n",
      "\titers: 200, epoch: 4 | loss: 0.5807631\n",
      "\tspeed: 0.0117s/iter; left time: 18.1350s\n",
      "Epoch: 4 cost time: 3.1508350372314453\n",
      "Epoch: 4, Steps: 249 | Train Loss: 0.6074129 Vali Loss: 1.6821728 Test Loss: 0.6861032\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh1_336_96_GLinear_ETTh1_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2545\n",
      "mse:0.6717222929000854, mae:0.5277197360992432\n"
     ]
    }
   ],
   "source": [
    "!python run_longExp.py \\\n",
    "  --is_training 1 \\\n",
    "  --model GLinear \\\n",
    "  --data ETTh1 \\\n",
    "  --root_path dataset/ \\\n",
    "  --data_path ETTh1.csv \\\n",
    "  --model_id ETTh1_336_96 \\\n",
    "  --seq_len 336 \\\n",
    "  --pred_len 336 \\\n",
    "  --batch_size 32 \\\n",
    "  --learning_rate 0.01 \\\n",
    "  --use_gpu True \\\n",
    "  --gpu 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1747864759572,
     "user": {
      "displayName": "amali amali",
      "userId": "15718090331232743656"
     },
     "user_tz": -60
    },
    "id": "uuoKQVyCJ0m-",
    "outputId": "4948c70d-7e39-45ee-cf2e-df6def11e8ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/MyProject_QMUL_Final\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/MyProject_QMUL_Final/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 119,
     "status": "ok",
     "timestamp": 1747864764358,
     "user": {
      "displayName": "amali amali",
      "userId": "15718090331232743656"
     },
     "user_tz": -60
    },
    "id": "ZftZXn3bcftK",
    "outputId": "53e154f0-809e-4eb7-a3c2-3315439bb625"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_basic.py  exp_main.py  exp_stat.py\t__pycache__\n"
     ]
    }
   ],
   "source": [
    "#!ls GLinear/exp/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1747864767442,
     "user": {
      "displayName": "amali amali",
      "userId": "15718090331232743656"
     },
     "user_tz": -60
    },
    "id": "cD2cS-iYcihs",
    "outputId": "fa39705c-df3e-4733-c23c-36fb5b97cae9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/MyProject_QMUL_Final/GLinear\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/MyProject_QMUL_Final/GLinear\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1747864769686,
     "user": {
      "displayName": "amali amali",
      "userId": "15718090331232743656"
     },
     "user_tz": -60
    },
    "id": "L-Oym9KLhbD9",
    "outputId": "151be3bd-95d4-4804-8cc1-654a385f962c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/MyProject_QMUL_Final/GLinear\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 41119,
     "status": "ok",
     "timestamp": 1747752532359,
     "user": {
      "displayName": "amali amali",
      "userId": "15718090331232743656"
     },
     "user_tz": -60
    },
    "id": "_-RLACocher8",
    "outputId": "50609c57-880f-49b9-9835-f04efa51529c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, train_only=False, model_id='ETTh1_336_96', model='GLinear', data='ETTh1', root_path='dataset/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='/spo/NewbornTime/tahir098/SVF/data/Extra/checkpoints/', seq_len=336, label_len=48, pred_len=336, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.01, des='test', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ETTh1_336_96_GLinear_ETTh1_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7969\n",
      "val 2545\n",
      "test 2545\n",
      "\titers: 100, epoch: 1 | loss: 0.7193723\n",
      "\tspeed: 0.0214s/iter; left time: 51.2460s\n",
      "\titers: 200, epoch: 1 | loss: 0.6215721\n",
      "\tspeed: 0.0060s/iter; left time: 13.8452s\n",
      "Epoch: 1 cost time: 1.9383304119110107\n",
      "Epoch: 1, Steps: 249 | Train Loss: 0.7064253 Vali Loss: 1.7137164 Test Loss: 0.6868615\n",
      "Validation loss decreased (inf --> 1.713716).  Saving model ...\n",
      "Updating learning rate to 0.01\n",
      "\titers: 100, epoch: 2 | loss: 0.6512136\n",
      "\tspeed: 0.0234s/iter; left time: 50.0359s\n",
      "\titers: 200, epoch: 2 | loss: 0.7420057\n",
      "\tspeed: 0.0062s/iter; left time: 12.5852s\n",
      "Epoch: 2 cost time: 1.7558929920196533\n",
      "Epoch: 2, Steps: 249 | Train Loss: 0.6962779 Vali Loss: 1.7350365 Test Loss: 0.6880316\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.005\n",
      "\titers: 100, epoch: 3 | loss: 0.6548854\n",
      "\tspeed: 0.0248s/iter; left time: 46.8847s\n",
      "\titers: 200, epoch: 3 | loss: 0.6697503\n",
      "\tspeed: 0.0064s/iter; left time: 11.4766s\n",
      "Epoch: 3 cost time: 1.7659306526184082\n",
      "Epoch: 3, Steps: 249 | Train Loss: 0.6686924 Vali Loss: 1.6899788 Test Loss: 0.6834799\n",
      "Validation loss decreased (1.713716 --> 1.689979).  Saving model ...\n",
      "Updating learning rate to 0.0025\n",
      "\titers: 100, epoch: 4 | loss: 0.6320267\n",
      "\tspeed: 0.0242s/iter; left time: 39.7210s\n",
      "\titers: 200, epoch: 4 | loss: 0.6152093\n",
      "\tspeed: 0.0061s/iter; left time: 9.3984s\n",
      "Epoch: 4 cost time: 1.7439167499542236\n",
      "Epoch: 4, Steps: 249 | Train Loss: 0.6397632 Vali Loss: 1.7279259 Test Loss: 0.6870098\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.00125\n",
      "\titers: 100, epoch: 5 | loss: 0.6347088\n",
      "\tspeed: 0.0238s/iter; left time: 33.2038s\n",
      "\titers: 200, epoch: 5 | loss: 0.6336316\n",
      "\tspeed: 0.0061s/iter; left time: 7.9466s\n",
      "Epoch: 5 cost time: 1.72525954246521\n",
      "Epoch: 5, Steps: 249 | Train Loss: 0.6203703 Vali Loss: 1.7762535 Test Loss: 0.6887510\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.000625\n",
      "\titers: 100, epoch: 6 | loss: 0.5929746\n",
      "\tspeed: 0.0234s/iter; left time: 26.8608s\n",
      "\titers: 200, epoch: 6 | loss: 0.5781485\n",
      "\tspeed: 0.0060s/iter; left time: 6.3208s\n",
      "Epoch: 6 cost time: 1.7328643798828125\n",
      "Epoch: 6, Steps: 249 | Train Loss: 0.6077853 Vali Loss: 1.7783135 Test Loss: 0.6896378\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh1_336_96_GLinear_ETTh1_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2545\n",
      "mse:0.6811772584915161, mae:0.5322288274765015\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ETTh1_336_96_GLinear_ETTh1_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7969\n",
      "val 2545\n",
      "test 2545\n",
      "\titers: 100, epoch: 1 | loss: 0.7482839\n",
      "\tspeed: 0.0082s/iter; left time: 19.4955s\n",
      "\titers: 200, epoch: 1 | loss: 0.6591691\n",
      "\tspeed: 0.0064s/iter; left time: 14.5629s\n",
      "Epoch: 1 cost time: 1.7960705757141113\n",
      "Epoch: 1, Steps: 249 | Train Loss: 0.7145678 Vali Loss: 1.6353669 Test Loss: 0.6859191\n",
      "Validation loss decreased (inf --> 1.635367).  Saving model ...\n",
      "Updating learning rate to 0.01\n",
      "\titers: 100, epoch: 2 | loss: 0.7742069\n",
      "\tspeed: 0.0252s/iter; left time: 53.9454s\n",
      "\titers: 200, epoch: 2 | loss: 0.7382012\n",
      "\tspeed: 0.0060s/iter; left time: 12.2729s\n",
      "Epoch: 2 cost time: 1.7234456539154053\n",
      "Epoch: 2, Steps: 249 | Train Loss: 0.6944920 Vali Loss: 1.6460057 Test Loss: 0.6938170\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.005\n",
      "\titers: 100, epoch: 3 | loss: 0.6602068\n",
      "\tspeed: 0.0255s/iter; left time: 48.3462s\n",
      "\titers: 200, epoch: 3 | loss: 0.7000718\n",
      "\tspeed: 0.0060s/iter; left time: 10.8221s\n",
      "Epoch: 3 cost time: 1.7569949626922607\n",
      "Epoch: 3, Steps: 249 | Train Loss: 0.6761713 Vali Loss: 1.6746567 Test Loss: 0.6796945\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0025\n",
      "\titers: 100, epoch: 4 | loss: 0.6557875\n",
      "\tspeed: 0.0267s/iter; left time: 43.8536s\n",
      "\titers: 200, epoch: 4 | loss: 0.6905285\n",
      "\tspeed: 0.0063s/iter; left time: 9.7048s\n",
      "Epoch: 4 cost time: 1.8109912872314453\n",
      "Epoch: 4, Steps: 249 | Train Loss: 0.6454310 Vali Loss: 1.6929866 Test Loss: 0.6819031\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh1_336_96_GLinear_ETTh1_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2545\n",
      "mse:0.6830269694328308, mae:0.532230794429779\n"
     ]
    }
   ],
   "source": [
    "!python run_longExp.py \\\n",
    "  --is_training 1 \\\n",
    "  --model GLinear \\\n",
    "  --data ETTh1 \\\n",
    "  --root_path dataset/ \\\n",
    "  --data_path ETTh1.csv \\\n",
    "  --model_id ETTh1_336_96 \\\n",
    "  --seq_len 336 \\\n",
    "  --pred_len 336 \\\n",
    "  --batch_size 32 \\\n",
    "  --learning_rate 0.01 \\\n",
    "  --use_gpu True \\\n",
    "  --gpu 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 41047,
     "status": "ok",
     "timestamp": 1747753725719,
     "user": {
      "displayName": "amali amali",
      "userId": "15718090331232743656"
     },
     "user_tz": -60
    },
    "id": "Hoo5CbLNh2Jl",
    "outputId": "7c46a4b2-b11e-49ca-e909-451c8ff63f53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/MyProject_QMUL_Final/GLinear\n",
      "âœ… Current directory: /content/drive/MyDrive/MyProject_QMUL_Final/GLinear\n",
      "Args in experiment:\n",
      "Namespace(is_training=1, train_only=False, model_id='ETTh1_336_96', model='GLinear', data='ETTh1', root_path='dataset/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='/spo/NewbornTime/tahir098/SVF/data/Extra/checkpoints/', seq_len=336, label_len=48, pred_len=336, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.01, des='test', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ETTh1_336_96_GLinear_ETTh1_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7969\n",
      "val 2545\n",
      "test 2545\n",
      "\titers: 100, epoch: 1 | loss: 0.7193723\n",
      "\tspeed: 0.0215s/iter; left time: 51.2937s\n",
      "\titers: 200, epoch: 1 | loss: 0.6215721\n",
      "\tspeed: 0.0061s/iter; left time: 14.0308s\n",
      "Epoch: 1 cost time: 1.9840359687805176\n",
      "Epoch: 1, Steps: 249 | Train Loss: 0.7064253 Vali Loss: 1.7137164 Test Loss: 0.6868615\n",
      "Validation loss decreased (inf --> 1.713716).  Saving model ...\n",
      "Updating learning rate to 0.01\n",
      "\titers: 100, epoch: 2 | loss: 0.6512136\n",
      "\tspeed: 0.0238s/iter; left time: 50.9192s\n",
      "\titers: 200, epoch: 2 | loss: 0.7420057\n",
      "\tspeed: 0.0064s/iter; left time: 13.0865s\n",
      "Epoch: 2 cost time: 1.8006181716918945\n",
      "Epoch: 2, Steps: 249 | Train Loss: 0.6962779 Vali Loss: 1.7350365 Test Loss: 0.6880316\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.005\n",
      "\titers: 100, epoch: 3 | loss: 0.6548854\n",
      "\tspeed: 0.0242s/iter; left time: 45.7519s\n",
      "\titers: 200, epoch: 3 | loss: 0.6697503\n",
      "\tspeed: 0.0061s/iter; left time: 10.8597s\n",
      "Epoch: 3 cost time: 1.7514917850494385\n",
      "Epoch: 3, Steps: 249 | Train Loss: 0.6686924 Vali Loss: 1.6899788 Test Loss: 0.6834799\n",
      "Validation loss decreased (1.713716 --> 1.689979).  Saving model ...\n",
      "Updating learning rate to 0.0025\n",
      "\titers: 100, epoch: 4 | loss: 0.6320267\n",
      "\tspeed: 0.0232s/iter; left time: 38.2075s\n",
      "\titers: 200, epoch: 4 | loss: 0.6152093\n",
      "\tspeed: 0.0061s/iter; left time: 9.4019s\n",
      "Epoch: 4 cost time: 1.7333524227142334\n",
      "Epoch: 4, Steps: 249 | Train Loss: 0.6397632 Vali Loss: 1.7279259 Test Loss: 0.6870098\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.00125\n",
      "\titers: 100, epoch: 5 | loss: 0.6347088\n",
      "\tspeed: 0.0241s/iter; left time: 33.5701s\n",
      "\titers: 200, epoch: 5 | loss: 0.6336316\n",
      "\tspeed: 0.0065s/iter; left time: 8.3865s\n",
      "Epoch: 5 cost time: 1.7903475761413574\n",
      "Epoch: 5, Steps: 249 | Train Loss: 0.6203703 Vali Loss: 1.7762535 Test Loss: 0.6887510\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.000625\n",
      "\titers: 100, epoch: 6 | loss: 0.5929746\n",
      "\tspeed: 0.0242s/iter; left time: 27.7259s\n",
      "\titers: 200, epoch: 6 | loss: 0.5781485\n",
      "\tspeed: 0.0062s/iter; left time: 6.5111s\n",
      "Epoch: 6 cost time: 1.765883207321167\n",
      "Epoch: 6, Steps: 249 | Train Loss: 0.6077853 Vali Loss: 1.7783135 Test Loss: 0.6896378\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh1_336_96_GLinear_ETTh1_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2545\n",
      "mse:0.6811772584915161, mae:0.5322288274765015\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ETTh1_336_96_GLinear_ETTh1_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7969\n",
      "val 2545\n",
      "test 2545\n",
      "\titers: 100, epoch: 1 | loss: 0.7482839\n",
      "\tspeed: 0.0080s/iter; left time: 19.1848s\n",
      "\titers: 200, epoch: 1 | loss: 0.6591691\n",
      "\tspeed: 0.0061s/iter; left time: 14.0302s\n",
      "Epoch: 1 cost time: 1.7578094005584717\n",
      "Epoch: 1, Steps: 249 | Train Loss: 0.7145678 Vali Loss: 1.6353669 Test Loss: 0.6859191\n",
      "Validation loss decreased (inf --> 1.635367).  Saving model ...\n",
      "Updating learning rate to 0.01\n",
      "\titers: 100, epoch: 2 | loss: 0.7742069\n",
      "\tspeed: 0.0257s/iter; left time: 54.9773s\n",
      "\titers: 200, epoch: 2 | loss: 0.7382012\n",
      "\tspeed: 0.0062s/iter; left time: 12.6581s\n",
      "Epoch: 2 cost time: 1.795037031173706\n",
      "Epoch: 2, Steps: 249 | Train Loss: 0.6944920 Vali Loss: 1.6460057 Test Loss: 0.6938170\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.005\n",
      "\titers: 100, epoch: 3 | loss: 0.6602068\n",
      "\tspeed: 0.0252s/iter; left time: 47.7957s\n",
      "\titers: 200, epoch: 3 | loss: 0.7000718\n",
      "\tspeed: 0.0062s/iter; left time: 11.1880s\n",
      "Epoch: 3 cost time: 1.7544357776641846\n",
      "Epoch: 3, Steps: 249 | Train Loss: 0.6761713 Vali Loss: 1.6746567 Test Loss: 0.6796945\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0025\n",
      "\titers: 100, epoch: 4 | loss: 0.6557875\n",
      "\tspeed: 0.0264s/iter; left time: 43.3982s\n",
      "\titers: 200, epoch: 4 | loss: 0.6905285\n",
      "\tspeed: 0.0062s/iter; left time: 9.5610s\n",
      "Epoch: 4 cost time: 1.7888822555541992\n",
      "Epoch: 4, Steps: 249 | Train Loss: 0.6454310 Vali Loss: 1.6929866 Test Loss: 0.6819031\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh1_336_96_GLinear_ETTh1_ftM_sl336_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2545\n",
      "mse:0.6830269694328308, mae:0.532230794429779\n",
      "\n",
      "ðŸ“ Saved experiments:\n",
      "exp_basic.py  exp_main.py  exp_stat.py\t__pycache__\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Go to the GLinear project folder\n",
    "%cd /content/drive/MyDrive/MyProject_QMUL_Final/GLinear\n",
    "\n",
    "# Step 2: Confirm working directory\n",
    "import os\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "\n",
    "# Step 3: Run training\n",
    "!python run_longExp.py \\\n",
    "  --is_training 1 \\\n",
    "  --model GLinear \\\n",
    "  --data ETTh1 \\\n",
    "  --root_path dataset/ \\\n",
    "  --data_path ETTh1.csv \\\n",
    "  --model_id ETTh1_336_96 \\\n",
    "  --seq_len 336 \\\n",
    "  --pred_len 336 \\\n",
    "  --batch_size 32 \\\n",
    "  --learning_rate 0.01 \\\n",
    "  --use_gpu True \\\n",
    "  --gpu 0\n",
    "\n",
    "\n",
    "# Step 4: Show saved experiment results\n",
    "print(\"\\nðŸ“ Saved experiments:\")\n",
    "!ls ./exp/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2HRkGyajqCst"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set path to one experiment result\n",
    "result_dir = \"/content/drive/MyDrive/MyProject_QMUL_Final/GLinear/results/ETTh1_336_96_GLinear_ETTh1_ftM_...\"\n",
    "\n",
    "# Load files\n",
    "pred = np.load(f\"{result_dir}/pred.npy\")\n",
    "true = np.load(f\"{result_dir}/true.npy\")\n",
    "\n",
    "print(\"Pred shape:\", pred.shape)\n",
    "print(\"True shape:\", true.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 217524,
     "status": "ok",
     "timestamp": 1747754551542,
     "user": {
      "displayName": "amali amali",
      "userId": "15718090331232743656"
     },
     "user_tz": -60
    },
    "id": "y3nxmL71BWE9",
    "outputId": "768c4a58-b22d-4355-a2e9-cf84eebaae07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/MyProject_QMUL_Final/GLinear\n",
      "âœ… Current directory: /content/drive/MyDrive/MyProject_QMUL_Final/GLinear\n",
      "Args in experiment:\n",
      "Namespace(is_training=1, train_only=False, model_id='ETTm1_336_96', model='GLinear', data='ETTm1', root_path='dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='/spo/NewbornTime/tahir098/SVF/data/Extra/checkpoints/', seq_len=336, label_len=48, pred_len=96, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.01, des='test', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ETTm1_336_96_GLinear_ETTm1_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 34129\n",
      "val 11425\n",
      "test 11425\n",
      "\titers: 100, epoch: 1 | loss: 0.3405250\n",
      "\tspeed: 0.0220s/iter; left time: 232.0463s\n",
      "\titers: 200, epoch: 1 | loss: 0.3239217\n",
      "\tspeed: 0.0062s/iter; left time: 64.7738s\n",
      "\titers: 300, epoch: 1 | loss: 0.3750216\n",
      "\tspeed: 0.0063s/iter; left time: 65.2001s\n",
      "\titers: 400, epoch: 1 | loss: 0.2849841\n",
      "\tspeed: 0.0062s/iter; left time: 63.5284s\n",
      "\titers: 500, epoch: 1 | loss: 0.3197758\n",
      "\tspeed: 0.0062s/iter; left time: 62.7170s\n",
      "\titers: 600, epoch: 1 | loss: 0.3301081\n",
      "\tspeed: 0.0060s/iter; left time: 59.8727s\n",
      "\titers: 700, epoch: 1 | loss: 0.3285947\n",
      "\tspeed: 0.0061s/iter; left time: 60.5189s\n",
      "\titers: 800, epoch: 1 | loss: 0.3334537\n",
      "\tspeed: 0.0061s/iter; left time: 59.7369s\n",
      "\titers: 900, epoch: 1 | loss: 0.3774807\n",
      "\tspeed: 0.0061s/iter; left time: 59.2856s\n",
      "\titers: 1000, epoch: 1 | loss: 0.3064182\n",
      "\tspeed: 0.0060s/iter; left time: 58.0183s\n",
      "Epoch: 1 cost time: 7.026270627975464\n",
      "Epoch: 1, Steps: 1066 | Train Loss: 0.3257698 Vali Loss: 0.4614012 Test Loss: 0.3733590\n",
      "Validation loss decreased (inf --> 0.461401).  Saving model ...\n",
      "Updating learning rate to 0.01\n",
      "\titers: 100, epoch: 2 | loss: 0.3038950\n",
      "\tspeed: 0.0454s/iter; left time: 431.2883s\n",
      "\titers: 200, epoch: 2 | loss: 0.3072135\n",
      "\tspeed: 0.0062s/iter; left time: 58.2861s\n",
      "\titers: 300, epoch: 2 | loss: 0.2810952\n",
      "\tspeed: 0.0063s/iter; left time: 58.5658s\n",
      "\titers: 400, epoch: 2 | loss: 0.3069686\n",
      "\tspeed: 0.0065s/iter; left time: 59.4901s\n",
      "\titers: 500, epoch: 2 | loss: 0.3422002\n",
      "\tspeed: 0.0061s/iter; left time: 55.8792s\n",
      "\titers: 600, epoch: 2 | loss: 0.4186510\n",
      "\tspeed: 0.0062s/iter; left time: 55.3474s\n",
      "\titers: 700, epoch: 2 | loss: 0.3324156\n",
      "\tspeed: 0.0059s/iter; left time: 52.6042s\n",
      "\titers: 800, epoch: 2 | loss: 0.3168497\n",
      "\tspeed: 0.0061s/iter; left time: 53.5510s\n",
      "\titers: 900, epoch: 2 | loss: 0.3318844\n",
      "\tspeed: 0.0062s/iter; left time: 53.7377s\n",
      "\titers: 1000, epoch: 2 | loss: 0.3298366\n",
      "\tspeed: 0.0061s/iter; left time: 52.1210s\n",
      "Epoch: 2 cost time: 6.817688226699829\n",
      "Epoch: 2, Steps: 1066 | Train Loss: 0.3229492 Vali Loss: 0.4485940 Test Loss: 0.3673951\n",
      "Validation loss decreased (0.461401 --> 0.448594).  Saving model ...\n",
      "Updating learning rate to 0.005\n",
      "\titers: 100, epoch: 3 | loss: 0.2693674\n",
      "\tspeed: 0.0475s/iter; left time: 400.7014s\n",
      "\titers: 200, epoch: 3 | loss: 0.3063555\n",
      "\tspeed: 0.0060s/iter; left time: 50.0820s\n",
      "\titers: 300, epoch: 3 | loss: 0.2845244\n",
      "\tspeed: 0.0059s/iter; left time: 48.9078s\n",
      "\titers: 400, epoch: 3 | loss: 0.3279458\n",
      "\tspeed: 0.0061s/iter; left time: 49.7975s\n",
      "\titers: 500, epoch: 3 | loss: 0.3411543\n",
      "\tspeed: 0.0064s/iter; left time: 51.3262s\n",
      "\titers: 600, epoch: 3 | loss: 0.3062220\n",
      "\tspeed: 0.0064s/iter; left time: 50.4969s\n",
      "\titers: 700, epoch: 3 | loss: 0.2891077\n",
      "\tspeed: 0.0065s/iter; left time: 50.5377s\n",
      "\titers: 800, epoch: 3 | loss: 0.2457825\n",
      "\tspeed: 0.0065s/iter; left time: 50.2294s\n",
      "\titers: 900, epoch: 3 | loss: 0.3005172\n",
      "\tspeed: 0.0061s/iter; left time: 46.3545s\n",
      "\titers: 1000, epoch: 3 | loss: 0.2771442\n",
      "\tspeed: 0.0062s/iter; left time: 46.8951s\n",
      "Epoch: 3 cost time: 6.833545684814453\n",
      "Epoch: 3, Steps: 1066 | Train Loss: 0.2949573 Vali Loss: 0.4433362 Test Loss: 0.3262993\n",
      "Validation loss decreased (0.448594 --> 0.443336).  Saving model ...\n",
      "Updating learning rate to 0.0025\n",
      "\titers: 100, epoch: 4 | loss: 0.2247066\n",
      "\tspeed: 0.0473s/iter; left time: 348.0389s\n",
      "\titers: 200, epoch: 4 | loss: 0.2411584\n",
      "\tspeed: 0.0062s/iter; left time: 45.0667s\n",
      "\titers: 300, epoch: 4 | loss: 0.3039196\n",
      "\tspeed: 0.0062s/iter; left time: 44.3987s\n",
      "\titers: 400, epoch: 4 | loss: 0.2471842\n",
      "\tspeed: 0.0061s/iter; left time: 43.1060s\n",
      "\titers: 500, epoch: 4 | loss: 0.2357992\n",
      "\tspeed: 0.0062s/iter; left time: 43.1179s\n",
      "\titers: 600, epoch: 4 | loss: 0.2796947\n",
      "\tspeed: 0.0062s/iter; left time: 42.3119s\n",
      "\titers: 700, epoch: 4 | loss: 0.2466439\n",
      "\tspeed: 0.0062s/iter; left time: 41.9387s\n",
      "\titers: 800, epoch: 4 | loss: 0.3166598\n",
      "\tspeed: 0.0062s/iter; left time: 41.6341s\n",
      "\titers: 900, epoch: 4 | loss: 0.2499274\n",
      "\tspeed: 0.0062s/iter; left time: 40.9018s\n",
      "\titers: 1000, epoch: 4 | loss: 0.2968558\n",
      "\tspeed: 0.0063s/iter; left time: 40.7916s\n",
      "Epoch: 4 cost time: 6.8285839557647705\n",
      "Epoch: 4, Steps: 1066 | Train Loss: 0.2836073 Vali Loss: 0.4121711 Test Loss: 0.3190594\n",
      "Validation loss decreased (0.443336 --> 0.412171).  Saving model ...\n",
      "Updating learning rate to 0.00125\n",
      "\titers: 100, epoch: 5 | loss: 0.2777781\n",
      "\tspeed: 0.0478s/iter; left time: 300.9369s\n",
      "\titers: 200, epoch: 5 | loss: 0.2190860\n",
      "\tspeed: 0.0062s/iter; left time: 38.6459s\n",
      "\titers: 300, epoch: 5 | loss: 0.2591342\n",
      "\tspeed: 0.0060s/iter; left time: 36.5108s\n",
      "\titers: 400, epoch: 5 | loss: 0.2358140\n",
      "\tspeed: 0.0062s/iter; left time: 37.2442s\n",
      "\titers: 500, epoch: 5 | loss: 0.2980509\n",
      "\tspeed: 0.0061s/iter; left time: 35.8207s\n",
      "\titers: 600, epoch: 5 | loss: 0.3070269\n",
      "\tspeed: 0.0061s/iter; left time: 35.6072s\n",
      "\titers: 700, epoch: 5 | loss: 0.3056968\n",
      "\tspeed: 0.0062s/iter; left time: 35.0585s\n",
      "\titers: 800, epoch: 5 | loss: 0.3029373\n",
      "\tspeed: 0.0062s/iter; left time: 34.8311s\n",
      "\titers: 900, epoch: 5 | loss: 0.3401235\n",
      "\tspeed: 0.0061s/iter; left time: 33.7224s\n",
      "\titers: 1000, epoch: 5 | loss: 0.2554230\n",
      "\tspeed: 0.0062s/iter; left time: 33.6311s\n",
      "Epoch: 5 cost time: 6.779138088226318\n",
      "Epoch: 5, Steps: 1066 | Train Loss: 0.2774606 Vali Loss: 0.3968242 Test Loss: 0.3090127\n",
      "Validation loss decreased (0.412171 --> 0.396824).  Saving model ...\n",
      "Updating learning rate to 0.000625\n",
      "\titers: 100, epoch: 6 | loss: 0.2925823\n",
      "\tspeed: 0.0477s/iter; left time: 249.6683s\n",
      "\titers: 200, epoch: 6 | loss: 0.3202053\n",
      "\tspeed: 0.0061s/iter; left time: 31.4730s\n",
      "\titers: 300, epoch: 6 | loss: 0.2940118\n",
      "\tspeed: 0.0063s/iter; left time: 31.5772s\n",
      "\titers: 400, epoch: 6 | loss: 0.2256235\n",
      "\tspeed: 0.0064s/iter; left time: 31.3511s\n",
      "\titers: 500, epoch: 6 | loss: 0.2767197\n",
      "\tspeed: 0.0065s/iter; left time: 31.4881s\n",
      "\titers: 600, epoch: 6 | loss: 0.2367112\n",
      "\tspeed: 0.0063s/iter; left time: 29.8752s\n",
      "\titers: 700, epoch: 6 | loss: 0.3111365\n",
      "\tspeed: 0.0061s/iter; left time: 28.3992s\n",
      "\titers: 800, epoch: 6 | loss: 0.2505244\n",
      "\tspeed: 0.0061s/iter; left time: 27.4583s\n",
      "\titers: 900, epoch: 6 | loss: 0.2872269\n",
      "\tspeed: 0.0059s/iter; left time: 26.2981s\n",
      "\titers: 1000, epoch: 6 | loss: 0.3190596\n",
      "\tspeed: 0.0063s/iter; left time: 27.1841s\n",
      "Epoch: 6 cost time: 6.840654611587524\n",
      "Epoch: 6, Steps: 1066 | Train Loss: 0.2741921 Vali Loss: 0.3860619 Test Loss: 0.3047783\n",
      "Validation loss decreased (0.396824 --> 0.386062).  Saving model ...\n",
      "Updating learning rate to 0.0003125\n",
      "\titers: 100, epoch: 7 | loss: 0.2550986\n",
      "\tspeed: 0.0483s/iter; left time: 201.0979s\n",
      "\titers: 200, epoch: 7 | loss: 0.3483312\n",
      "\tspeed: 0.0062s/iter; left time: 25.3835s\n",
      "\titers: 300, epoch: 7 | loss: 0.2562622\n",
      "\tspeed: 0.0062s/iter; left time: 24.4530s\n",
      "\titers: 400, epoch: 7 | loss: 0.2482514\n",
      "\tspeed: 0.0062s/iter; left time: 24.1212s\n",
      "\titers: 500, epoch: 7 | loss: 0.2742609\n",
      "\tspeed: 0.0061s/iter; left time: 23.0047s\n",
      "\titers: 600, epoch: 7 | loss: 0.2981653\n",
      "\tspeed: 0.0063s/iter; left time: 22.9939s\n",
      "\titers: 700, epoch: 7 | loss: 0.2500526\n",
      "\tspeed: 0.0061s/iter; left time: 21.6336s\n",
      "\titers: 800, epoch: 7 | loss: 0.3316194\n",
      "\tspeed: 0.0062s/iter; left time: 21.5154s\n",
      "\titers: 900, epoch: 7 | loss: 0.2878182\n",
      "\tspeed: 0.0061s/iter; left time: 20.6120s\n",
      "\titers: 1000, epoch: 7 | loss: 0.2229175\n",
      "\tspeed: 0.0063s/iter; left time: 20.4958s\n",
      "Epoch: 7 cost time: 6.836130857467651\n",
      "Epoch: 7, Steps: 1066 | Train Loss: 0.2721901 Vali Loss: 0.3996381 Test Loss: 0.3025881\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.00015625\n",
      "\titers: 100, epoch: 8 | loss: 0.2273310\n",
      "\tspeed: 0.0469s/iter; left time: 145.4234s\n",
      "\titers: 200, epoch: 8 | loss: 0.2993229\n",
      "\tspeed: 0.0062s/iter; left time: 18.7408s\n",
      "\titers: 300, epoch: 8 | loss: 0.2326166\n",
      "\tspeed: 0.0062s/iter; left time: 18.0277s\n",
      "\titers: 400, epoch: 8 | loss: 0.2573721\n",
      "\tspeed: 0.0064s/iter; left time: 17.8566s\n",
      "\titers: 500, epoch: 8 | loss: 0.2423292\n",
      "\tspeed: 0.0064s/iter; left time: 17.3436s\n",
      "\titers: 600, epoch: 8 | loss: 0.2625947\n",
      "\tspeed: 0.0062s/iter; left time: 16.2147s\n",
      "\titers: 700, epoch: 8 | loss: 0.2741612\n",
      "\tspeed: 0.0063s/iter; left time: 15.6214s\n",
      "\titers: 800, epoch: 8 | loss: 0.2597878\n",
      "\tspeed: 0.0063s/iter; left time: 15.1710s\n",
      "\titers: 900, epoch: 8 | loss: 0.2762343\n",
      "\tspeed: 0.0063s/iter; left time: 14.4627s\n",
      "\titers: 1000, epoch: 8 | loss: 0.2653229\n",
      "\tspeed: 0.0062s/iter; left time: 13.6116s\n",
      "Epoch: 8 cost time: 6.9598915576934814\n",
      "Epoch: 8, Steps: 1066 | Train Loss: 0.2711984 Vali Loss: 0.3900827 Test Loss: 0.3004790\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2697979\n",
      "\tspeed: 0.0464s/iter; left time: 94.3866s\n",
      "\titers: 200, epoch: 9 | loss: 0.2758249\n",
      "\tspeed: 0.0061s/iter; left time: 11.8370s\n",
      "\titers: 300, epoch: 9 | loss: 0.2215768\n",
      "\tspeed: 0.0063s/iter; left time: 11.5348s\n",
      "\titers: 400, epoch: 9 | loss: 0.2177511\n",
      "\tspeed: 0.0059s/iter; left time: 10.3075s\n",
      "\titers: 500, epoch: 9 | loss: 0.2482623\n",
      "\tspeed: 0.0064s/iter; left time: 10.4307s\n",
      "\titers: 600, epoch: 9 | loss: 0.2597755\n",
      "\tspeed: 0.0063s/iter; left time: 9.5986s\n",
      "\titers: 700, epoch: 9 | loss: 0.2915817\n",
      "\tspeed: 0.0062s/iter; left time: 8.8417s\n",
      "\titers: 800, epoch: 9 | loss: 0.2883221\n",
      "\tspeed: 0.0064s/iter; left time: 8.5370s\n",
      "\titers: 900, epoch: 9 | loss: 0.2636820\n",
      "\tspeed: 0.0061s/iter; left time: 7.5759s\n",
      "\titers: 1000, epoch: 9 | loss: 0.2652803\n",
      "\tspeed: 0.0060s/iter; left time: 6.8222s\n",
      "Epoch: 9 cost time: 6.819796085357666\n",
      "Epoch: 9, Steps: 1066 | Train Loss: 0.2706726 Vali Loss: 0.3902009 Test Loss: 0.3013236\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTm1_336_96_GLinear_ETTm1_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 11425\n",
      "mse:0.3054329454898834, mae:0.34636133909225464\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ETTm1_336_96_GLinear_ETTm1_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 34129\n",
      "val 11425\n",
      "test 11425\n",
      "\titers: 100, epoch: 1 | loss: 0.2576402\n",
      "\tspeed: 0.0088s/iter; left time: 93.2166s\n",
      "\titers: 200, epoch: 1 | loss: 0.3539855\n",
      "\tspeed: 0.0065s/iter; left time: 68.2698s\n",
      "\titers: 300, epoch: 1 | loss: 0.2979206\n",
      "\tspeed: 0.0063s/iter; left time: 65.4858s\n",
      "\titers: 400, epoch: 1 | loss: 0.3146684\n",
      "\tspeed: 0.0063s/iter; left time: 64.7283s\n",
      "\titers: 500, epoch: 1 | loss: 0.2686085\n",
      "\tspeed: 0.0062s/iter; left time: 63.3081s\n",
      "\titers: 600, epoch: 1 | loss: 0.3777961\n",
      "\tspeed: 0.0062s/iter; left time: 62.6691s\n",
      "\titers: 700, epoch: 1 | loss: 0.2874791\n",
      "\tspeed: 0.0062s/iter; left time: 61.8368s\n",
      "\titers: 800, epoch: 1 | loss: 0.3356703\n",
      "\tspeed: 0.0062s/iter; left time: 61.0893s\n",
      "\titers: 900, epoch: 1 | loss: 0.4866308\n",
      "\tspeed: 0.0061s/iter; left time: 59.5259s\n",
      "\titers: 1000, epoch: 1 | loss: 0.2908970\n",
      "\tspeed: 0.0063s/iter; left time: 60.7446s\n",
      "Epoch: 1 cost time: 6.965266466140747\n",
      "Epoch: 1, Steps: 1066 | Train Loss: 0.3269264 Vali Loss: 0.5087400 Test Loss: 0.3866019\n",
      "Validation loss decreased (inf --> 0.508740).  Saving model ...\n",
      "Updating learning rate to 0.01\n",
      "\titers: 100, epoch: 2 | loss: 0.3532103\n",
      "\tspeed: 0.0503s/iter; left time: 477.1962s\n",
      "\titers: 200, epoch: 2 | loss: 0.4078010\n",
      "\tspeed: 0.0063s/iter; left time: 59.5175s\n",
      "\titers: 300, epoch: 2 | loss: 0.3210663\n",
      "\tspeed: 0.0067s/iter; left time: 62.3342s\n",
      "\titers: 400, epoch: 2 | loss: 0.3703842\n",
      "\tspeed: 0.0066s/iter; left time: 60.9868s\n",
      "\titers: 500, epoch: 2 | loss: 0.3958030\n",
      "\tspeed: 0.0065s/iter; left time: 59.3828s\n",
      "\titers: 600, epoch: 2 | loss: 0.3079167\n",
      "\tspeed: 0.0064s/iter; left time: 57.4905s\n",
      "\titers: 700, epoch: 2 | loss: 0.3108484\n",
      "\tspeed: 0.0060s/iter; left time: 53.7758s\n",
      "\titers: 800, epoch: 2 | loss: 0.2876133\n",
      "\tspeed: 0.0064s/iter; left time: 56.1217s\n",
      "\titers: 900, epoch: 2 | loss: 0.3160633\n",
      "\tspeed: 0.0061s/iter; left time: 53.0298s\n",
      "\titers: 1000, epoch: 2 | loss: 0.2596210\n",
      "\tspeed: 0.0065s/iter; left time: 56.2830s\n",
      "Epoch: 2 cost time: 7.075192451477051\n",
      "Epoch: 2, Steps: 1066 | Train Loss: 0.3856559 Vali Loss: 0.4417652 Test Loss: 0.3706368\n",
      "Validation loss decreased (0.508740 --> 0.441765).  Saving model ...\n",
      "Updating learning rate to 0.005\n",
      "\titers: 100, epoch: 3 | loss: 0.2505455\n",
      "\tspeed: 0.0504s/iter; left time: 424.5899s\n",
      "\titers: 200, epoch: 3 | loss: 0.2380119\n",
      "\tspeed: 0.0065s/iter; left time: 54.4791s\n",
      "\titers: 300, epoch: 3 | loss: 0.2682218\n",
      "\tspeed: 0.0066s/iter; left time: 54.6709s\n",
      "\titers: 400, epoch: 3 | loss: 0.3091704\n",
      "\tspeed: 0.0067s/iter; left time: 54.2719s\n",
      "\titers: 500, epoch: 3 | loss: 0.2967342\n",
      "\tspeed: 0.0065s/iter; left time: 52.5562s\n",
      "\titers: 600, epoch: 3 | loss: 0.2538384\n",
      "\tspeed: 0.0064s/iter; left time: 50.9776s\n",
      "\titers: 700, epoch: 3 | loss: 0.2977207\n",
      "\tspeed: 0.0066s/iter; left time: 51.8959s\n",
      "\titers: 800, epoch: 3 | loss: 0.2982517\n",
      "\tspeed: 0.0062s/iter; left time: 48.2856s\n",
      "\titers: 900, epoch: 3 | loss: 0.3147734\n",
      "\tspeed: 0.0064s/iter; left time: 48.6802s\n",
      "\titers: 1000, epoch: 3 | loss: 0.2615056\n",
      "\tspeed: 0.0062s/iter; left time: 46.5752s\n",
      "Epoch: 3 cost time: 7.15339469909668\n",
      "Epoch: 3, Steps: 1066 | Train Loss: 0.2939703 Vali Loss: 0.4183594 Test Loss: 0.3345878\n",
      "Validation loss decreased (0.441765 --> 0.418359).  Saving model ...\n",
      "Updating learning rate to 0.0025\n",
      "\titers: 100, epoch: 4 | loss: 0.2527822\n",
      "\tspeed: 0.0496s/iter; left time: 365.3167s\n",
      "\titers: 200, epoch: 4 | loss: 0.3022802\n",
      "\tspeed: 0.0061s/iter; left time: 44.6043s\n",
      "\titers: 300, epoch: 4 | loss: 0.2659241\n",
      "\tspeed: 0.0061s/iter; left time: 44.0469s\n",
      "\titers: 400, epoch: 4 | loss: 0.2592252\n",
      "\tspeed: 0.0060s/iter; left time: 42.6039s\n",
      "\titers: 500, epoch: 4 | loss: 0.2558551\n",
      "\tspeed: 0.0060s/iter; left time: 42.0673s\n",
      "\titers: 600, epoch: 4 | loss: 0.2931408\n",
      "\tspeed: 0.0063s/iter; left time: 43.1862s\n",
      "\titers: 700, epoch: 4 | loss: 0.2759301\n",
      "\tspeed: 0.0064s/iter; left time: 43.0137s\n",
      "\titers: 800, epoch: 4 | loss: 0.2440477\n",
      "\tspeed: 0.0065s/iter; left time: 43.1533s\n",
      "\titers: 900, epoch: 4 | loss: 0.3262903\n",
      "\tspeed: 0.0063s/iter; left time: 41.6196s\n",
      "\titers: 1000, epoch: 4 | loss: 0.2780852\n",
      "\tspeed: 0.0067s/iter; left time: 43.3592s\n",
      "Epoch: 4 cost time: 6.969772815704346\n",
      "Epoch: 4, Steps: 1066 | Train Loss: 0.2834182 Vali Loss: 0.4011472 Test Loss: 0.3141138\n",
      "Validation loss decreased (0.418359 --> 0.401147).  Saving model ...\n",
      "Updating learning rate to 0.00125\n",
      "\titers: 100, epoch: 5 | loss: 0.3277771\n",
      "\tspeed: 0.0500s/iter; left time: 314.9170s\n",
      "\titers: 200, epoch: 5 | loss: 0.3048182\n",
      "\tspeed: 0.0062s/iter; left time: 38.6676s\n",
      "\titers: 300, epoch: 5 | loss: 0.2189850\n",
      "\tspeed: 0.0061s/iter; left time: 37.3779s\n",
      "\titers: 400, epoch: 5 | loss: 0.3266218\n",
      "\tspeed: 0.0062s/iter; left time: 37.0376s\n",
      "\titers: 500, epoch: 5 | loss: 0.2596035\n",
      "\tspeed: 0.0062s/iter; left time: 36.6657s\n",
      "\titers: 600, epoch: 5 | loss: 0.2271194\n",
      "\tspeed: 0.0061s/iter; left time: 35.4223s\n",
      "\titers: 700, epoch: 5 | loss: 0.2408155\n",
      "\tspeed: 0.0064s/iter; left time: 36.7183s\n",
      "\titers: 800, epoch: 5 | loss: 0.2187109\n",
      "\tspeed: 0.0062s/iter; left time: 34.6238s\n",
      "\titers: 900, epoch: 5 | loss: 0.2274680\n",
      "\tspeed: 0.0062s/iter; left time: 33.9610s\n",
      "\titers: 1000, epoch: 5 | loss: 0.2955232\n",
      "\tspeed: 0.0063s/iter; left time: 34.0547s\n",
      "Epoch: 5 cost time: 6.925441741943359\n",
      "Epoch: 5, Steps: 1066 | Train Loss: 0.2776375 Vali Loss: 0.4186977 Test Loss: 0.3099425\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.000625\n",
      "\titers: 100, epoch: 6 | loss: 0.2317464\n",
      "\tspeed: 0.0512s/iter; left time: 267.9860s\n",
      "\titers: 200, epoch: 6 | loss: 0.2186524\n",
      "\tspeed: 0.0062s/iter; left time: 31.8720s\n",
      "\titers: 300, epoch: 6 | loss: 0.3156412\n",
      "\tspeed: 0.0062s/iter; left time: 31.2470s\n",
      "\titers: 400, epoch: 6 | loss: 0.3589285\n",
      "\tspeed: 0.0060s/iter; left time: 29.3953s\n",
      "\titers: 500, epoch: 6 | loss: 0.2555168\n",
      "\tspeed: 0.0062s/iter; left time: 30.0346s\n",
      "\titers: 600, epoch: 6 | loss: 0.3250273\n",
      "\tspeed: 0.0060s/iter; left time: 28.5293s\n",
      "\titers: 700, epoch: 6 | loss: 0.2528187\n",
      "\tspeed: 0.0061s/iter; left time: 28.2627s\n",
      "\titers: 800, epoch: 6 | loss: 0.3154817\n",
      "\tspeed: 0.0062s/iter; left time: 28.1122s\n",
      "\titers: 900, epoch: 6 | loss: 0.2896151\n",
      "\tspeed: 0.0061s/iter; left time: 27.2116s\n",
      "\titers: 1000, epoch: 6 | loss: 0.2998402\n",
      "\tspeed: 0.0063s/iter; left time: 27.1764s\n",
      "Epoch: 6 cost time: 6.851820468902588\n",
      "Epoch: 6, Steps: 1066 | Train Loss: 0.2740881 Vali Loss: 0.3992038 Test Loss: 0.3022894\n",
      "Validation loss decreased (0.401147 --> 0.399204).  Saving model ...\n",
      "Updating learning rate to 0.0003125\n",
      "\titers: 100, epoch: 7 | loss: 0.2598431\n",
      "\tspeed: 0.0512s/iter; left time: 213.1490s\n",
      "\titers: 200, epoch: 7 | loss: 0.2756478\n",
      "\tspeed: 0.0063s/iter; left time: 25.4500s\n",
      "\titers: 300, epoch: 7 | loss: 0.2400171\n",
      "\tspeed: 0.0062s/iter; left time: 24.6521s\n",
      "\titers: 400, epoch: 7 | loss: 0.2225500\n",
      "\tspeed: 0.0062s/iter; left time: 24.0340s\n",
      "\titers: 500, epoch: 7 | loss: 0.2969522\n",
      "\tspeed: 0.0061s/iter; left time: 22.9800s\n",
      "\titers: 600, epoch: 7 | loss: 0.1949147\n",
      "\tspeed: 0.0062s/iter; left time: 22.8485s\n",
      "\titers: 700, epoch: 7 | loss: 0.2558097\n",
      "\tspeed: 0.0061s/iter; left time: 21.8573s\n",
      "\titers: 800, epoch: 7 | loss: 0.2671631\n",
      "\tspeed: 0.0062s/iter; left time: 21.5761s\n",
      "\titers: 900, epoch: 7 | loss: 0.2322572\n",
      "\tspeed: 0.0060s/iter; left time: 20.0814s\n",
      "\titers: 1000, epoch: 7 | loss: 0.2730588\n",
      "\tspeed: 0.0061s/iter; left time: 20.0668s\n",
      "Epoch: 7 cost time: 6.843438148498535\n",
      "Epoch: 7, Steps: 1066 | Train Loss: 0.2722284 Vali Loss: 0.3908717 Test Loss: 0.3029226\n",
      "Validation loss decreased (0.399204 --> 0.390872).  Saving model ...\n",
      "Updating learning rate to 0.00015625\n",
      "\titers: 100, epoch: 8 | loss: 0.2715499\n",
      "\tspeed: 0.0504s/iter; left time: 156.1011s\n",
      "\titers: 200, epoch: 8 | loss: 0.2007123\n",
      "\tspeed: 0.0065s/iter; left time: 19.4918s\n",
      "\titers: 300, epoch: 8 | loss: 0.3236811\n",
      "\tspeed: 0.0063s/iter; left time: 18.1894s\n",
      "\titers: 400, epoch: 8 | loss: 0.2901543\n",
      "\tspeed: 0.0063s/iter; left time: 17.5771s\n",
      "\titers: 500, epoch: 8 | loss: 0.2836015\n",
      "\tspeed: 0.0063s/iter; left time: 17.0388s\n",
      "\titers: 600, epoch: 8 | loss: 0.2494548\n",
      "\tspeed: 0.0061s/iter; left time: 15.9793s\n",
      "\titers: 700, epoch: 8 | loss: 0.2955985\n",
      "\tspeed: 0.0062s/iter; left time: 15.5161s\n",
      "\titers: 800, epoch: 8 | loss: 0.2541389\n",
      "\tspeed: 0.0063s/iter; left time: 15.1836s\n",
      "\titers: 900, epoch: 8 | loss: 0.2784378\n",
      "\tspeed: 0.0061s/iter; left time: 13.9217s\n",
      "\titers: 1000, epoch: 8 | loss: 0.2451327\n",
      "\tspeed: 0.0063s/iter; left time: 13.8734s\n",
      "Epoch: 8 cost time: 6.937252521514893\n",
      "Epoch: 8, Steps: 1066 | Train Loss: 0.2712086 Vali Loss: 0.3945347 Test Loss: 0.2995745\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.3136624\n",
      "\tspeed: 0.0495s/iter; left time: 100.5446s\n",
      "\titers: 200, epoch: 9 | loss: 0.2587309\n",
      "\tspeed: 0.0066s/iter; left time: 12.6822s\n",
      "\titers: 300, epoch: 9 | loss: 0.2966500\n",
      "\tspeed: 0.0063s/iter; left time: 11.5521s\n",
      "\titers: 400, epoch: 9 | loss: 0.2259542\n",
      "\tspeed: 0.0066s/iter; left time: 11.3874s\n",
      "\titers: 500, epoch: 9 | loss: 0.2406161\n",
      "\tspeed: 0.0063s/iter; left time: 10.3031s\n",
      "\titers: 600, epoch: 9 | loss: 0.2455352\n",
      "\tspeed: 0.0062s/iter; left time: 9.4463s\n",
      "\titers: 700, epoch: 9 | loss: 0.2752010\n",
      "\tspeed: 0.0062s/iter; left time: 8.9107s\n",
      "\titers: 800, epoch: 9 | loss: 0.2874425\n",
      "\tspeed: 0.0062s/iter; left time: 8.2770s\n",
      "\titers: 900, epoch: 9 | loss: 0.2418173\n",
      "\tspeed: 0.0061s/iter; left time: 7.5776s\n",
      "\titers: 1000, epoch: 9 | loss: 0.2657619\n",
      "\tspeed: 0.0062s/iter; left time: 7.0093s\n",
      "Epoch: 9 cost time: 6.958603858947754\n",
      "Epoch: 9, Steps: 1066 | Train Loss: 0.2706194 Vali Loss: 0.3918803 Test Loss: 0.3001249\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2187337\n",
      "\tspeed: 0.0499s/iter; left time: 48.2076s\n",
      "\titers: 200, epoch: 10 | loss: 0.2710400\n",
      "\tspeed: 0.0063s/iter; left time: 5.4694s\n",
      "\titers: 300, epoch: 10 | loss: 0.2199778\n",
      "\tspeed: 0.0062s/iter; left time: 4.7553s\n",
      "\titers: 400, epoch: 10 | loss: 0.2156097\n",
      "\tspeed: 0.0063s/iter; left time: 4.1707s\n",
      "\titers: 500, epoch: 10 | loss: 0.3166126\n",
      "\tspeed: 0.0064s/iter; left time: 3.6516s\n",
      "\titers: 600, epoch: 10 | loss: 0.2678502\n",
      "\tspeed: 0.0064s/iter; left time: 2.9837s\n",
      "\titers: 700, epoch: 10 | loss: 0.2784802\n",
      "\tspeed: 0.0065s/iter; left time: 2.3680s\n",
      "\titers: 800, epoch: 10 | loss: 0.2614485\n",
      "\tspeed: 0.0064s/iter; left time: 1.7131s\n",
      "\titers: 900, epoch: 10 | loss: 0.3281319\n",
      "\tspeed: 0.0061s/iter; left time: 1.0118s\n",
      "\titers: 1000, epoch: 10 | loss: 0.2014568\n",
      "\tspeed: 0.0062s/iter; left time: 0.4131s\n",
      "Epoch: 10 cost time: 6.95603346824646\n",
      "Epoch: 10, Steps: 1066 | Train Loss: 0.2704148 Vali Loss: 0.3908658 Test Loss: 0.2998835\n",
      "Validation loss decreased (0.390872 --> 0.390866).  Saving model ...\n",
      "Updating learning rate to 1.953125e-05\n",
      ">>>>>>>testing : ETTm1_336_96_GLinear_ETTm1_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 11425\n",
      "mse:0.30047085881233215, mae:0.3424658179283142\n",
      "\n",
      "ðŸ“ Saved experiments:\n",
      "exp_basic.py  exp_main.py  exp_stat.py\t__pycache__\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Go to the GLinear project folder\n",
    "%cd /content/drive/MyDrive/MyProject_QMUL_Final/GLinear\n",
    "\n",
    "# Step 2: Confirm working directory\n",
    "import os\n",
    "print(\"âœ… Current directory:\", os.getcwd())\n",
    "\n",
    "# Step 3: Run training\n",
    "!python run_longExp.py \\\n",
    "  --is_training 1 \\\n",
    "  --model GLinear \\\n",
    "  --data ETTm1 \\\n",
    "  --root_path dataset/ \\\n",
    "  --data_path ETTm1.csv \\\n",
    "  --model_id ETTm1_336_96 \\\n",
    "  --seq_len 336 \\\n",
    "  --pred_len 96 \\\n",
    "  --batch_size 32 \\\n",
    "  --learning_rate 0.01 \\\n",
    "  --use_gpu True \\\n",
    "  --gpu 0\n",
    "\n",
    "\n",
    "# Step 4: Show saved experiment results\n",
    "print(\"\\nðŸ“ Saved experiments:\")\n",
    "!ls ./exp/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 27088,
     "status": "ok",
     "timestamp": 1747783110993,
     "user": {
      "displayName": "amali amali",
      "userId": "15718090331232743656"
     },
     "user_tz": -60
    },
    "id": "QkJ_K8e5YSa9",
    "outputId": "b88f8754-192f-4ad6-f127-e6e038ab80f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, train_only=False, model_id='Exchange_336_96', model='GLinear', data='custom', root_path='dataset/', data_path='exchange_rate.csv', features='M', target='OT', freq='h', checkpoints='/spo/NewbornTime/tahir098/SVF/data/Extra/checkpoints/', seq_len=336, label_len=48, pred_len=96, individual=False, embed_type=0, enc_in=8, dec_in=8, c_out=8, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des='test', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Exchange_336_96_GLinear_custom_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 4880\n",
      "val 665\n",
      "test 1422\n",
      "\titers: 100, epoch: 1 | loss: 0.0871365\n",
      "\tspeed: 0.0220s/iter; left time: 31.2722s\n",
      "Epoch: 1 cost time: 1.424112319946289\n",
      "Epoch: 1, Steps: 152 | Train Loss: 0.1472084 Vali Loss: 0.1483645 Test Loss: 0.1027700\n",
      "Validation loss decreased (inf --> 0.148364).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "\titers: 100, epoch: 2 | loss: 0.0855763\n",
      "\tspeed: 0.0180s/iter; left time: 22.8656s\n",
      "Epoch: 2 cost time: 1.152000904083252\n",
      "Epoch: 2, Steps: 152 | Train Loss: 0.1086983 Vali Loss: 0.1724278 Test Loss: 0.1030151\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0005\n",
      "\titers: 100, epoch: 3 | loss: 0.1060769\n",
      "\tspeed: 0.0188s/iter; left time: 21.0287s\n",
      "Epoch: 3 cost time: 1.170158863067627\n",
      "Epoch: 3, Steps: 152 | Train Loss: 0.0827583 Vali Loss: 0.2086837 Test Loss: 0.1083579\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.00025\n",
      "\titers: 100, epoch: 4 | loss: 0.0475213\n",
      "\tspeed: 0.0185s/iter; left time: 17.8899s\n",
      "Epoch: 4 cost time: 1.1504120826721191\n",
      "Epoch: 4, Steps: 152 | Train Loss: 0.0644597 Vali Loss: 0.2169817 Test Loss: 0.1152663\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : Exchange_336_96_GLinear_custom_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 1422\n",
      "mse:0.10275311022996902, mae:0.22908979654312134\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Exchange_336_96_GLinear_custom_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 4880\n",
      "val 665\n",
      "test 1422\n",
      "\titers: 100, epoch: 1 | loss: 0.1320595\n",
      "\tspeed: 0.0084s/iter; left time: 11.9751s\n",
      "Epoch: 1 cost time: 1.2199864387512207\n",
      "Epoch: 1, Steps: 152 | Train Loss: 0.1434635 Vali Loss: 0.1645536 Test Loss: 0.1039246\n",
      "Validation loss decreased (inf --> 0.164554).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "\titers: 100, epoch: 2 | loss: 0.1164293\n",
      "\tspeed: 0.0191s/iter; left time: 24.2435s\n",
      "Epoch: 2 cost time: 1.183596134185791\n",
      "Epoch: 2, Steps: 152 | Train Loss: 0.1059522 Vali Loss: 0.1773638 Test Loss: 0.0997929\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0005\n",
      "\titers: 100, epoch: 3 | loss: 0.0850288\n",
      "\tspeed: 0.0190s/iter; left time: 21.2387s\n",
      "Epoch: 3 cost time: 1.20308518409729\n",
      "Epoch: 3, Steps: 152 | Train Loss: 0.0805897 Vali Loss: 0.1985567 Test Loss: 0.1099054\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.00025\n",
      "\titers: 100, epoch: 4 | loss: 0.0608279\n",
      "\tspeed: 0.0197s/iter; left time: 19.0382s\n",
      "Epoch: 4 cost time: 1.2486670017242432\n",
      "Epoch: 4, Steps: 152 | Train Loss: 0.0646415 Vali Loss: 0.2269330 Test Loss: 0.1187524\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : Exchange_336_96_GLinear_custom_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 1422\n",
      "mse:0.10359647125005722, mae:0.22940005362033844\n"
     ]
    }
   ],
   "source": [
    "!python run_longExp.py \\\n",
    "  --is_training 1 \\\n",
    "  --model GLinear \\\n",
    "  --data custom \\\n",
    "  --root_path dataset/ \\\n",
    "  --data_path exchange_rate.csv \\\n",
    "  --model_id Exchange_336_96 \\\n",
    "  --features M \\\n",
    "  --target OT \\\n",
    "  --seq_len 336 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --enc_in 8 \\\n",
    "  --dec_in 8 \\\n",
    "  --c_out 8 \\\n",
    "  --batch_size 32 \\\n",
    "  --learning_rate 0.001 \\\n",
    "  --use_gpu True \\\n",
    "  --gpu 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 107,
     "status": "ok",
     "timestamp": 1747782647318,
     "user": {
      "displayName": "amali amali",
      "userId": "15718090331232743656"
     },
     "user_tz": -60
    },
    "id": "gY1YXsE0bPN1",
    "outputId": "2f438970-01ea-4cb4-9f1f-5ccf46550991"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3: can't open file '/content/drive/MyDrive/MyProject_QMUL_Final/run_longExp.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python run_longExp.py \\\n",
    "  --is_training 1 \\\n",
    "  --model GLinear \\\n",
    "  --data custom \\\n",
    "  --root_path dataset/ \\\n",
    "  --data_path electricity.csv \\\n",
    "  --model_id Electricity_336_96 \\\n",
    "  --features M \\\n",
    "  --target OT \\\n",
    "  --seq_len 336 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --enc_in 321 \\\n",
    "  --dec_in 321 \\\n",
    "  --c_out 321 \\\n",
    "  --batch_size 32 \\\n",
    "  --learning_rate 0.001 \\\n",
    "  --use_gpu True \\\n",
    "  --gpu 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1161650,
     "status": "ok",
     "timestamp": 1747867170039,
     "user": {
      "displayName": "amali amali",
      "userId": "15718090331232743656"
     },
     "user_tz": -60
    },
    "id": "kU1lCyZbk_ZE",
    "outputId": "9bac7035-c962-4244-99cc-75b95e50724c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, train_only=False, model_id='Traffic_336_96', model='GLinear', data='custom', root_path='dataset/', data_path='traffic.csv', features='M', target='OT', freq='h', checkpoints='/spo/NewbornTime/tahir098/SVF/data/Extra/checkpoints/', seq_len=336, label_len=48, pred_len=720, individual=False, embed_type=0, enc_in=862, dec_in=862, c_out=862, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.01, des='test', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Traffic_336_96_GLinear_custom_ftM_sl336_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 11225\n",
      "val 1037\n",
      "test 2789\n",
      "\titers: 100, epoch: 1 | loss: 0.3212279\n",
      "\tspeed: 0.1240s/iter; left time: 421.5745s\n",
      "\titers: 200, epoch: 1 | loss: 0.3043400\n",
      "\tspeed: 0.1081s/iter; left time: 356.7649s\n",
      "\titers: 300, epoch: 1 | loss: 0.3135245\n",
      "\tspeed: 0.1094s/iter; left time: 350.0631s\n",
      "Epoch: 1 cost time: 38.75820183753967\n",
      "Epoch: 1, Steps: 350 | Train Loss: 0.3369219 Vali Loss: 0.4366924 Test Loss: 0.5080792\n",
      "Validation loss decreased (inf --> 0.436692).  Saving model ...\n",
      "Updating learning rate to 0.01\n",
      "\titers: 100, epoch: 2 | loss: 0.3447751\n",
      "\tspeed: 0.5314s/iter; left time: 1621.4300s\n",
      "\titers: 200, epoch: 2 | loss: 0.3173255\n",
      "\tspeed: 0.1084s/iter; left time: 319.8099s\n",
      "\titers: 300, epoch: 2 | loss: 0.2911749\n",
      "\tspeed: 0.1099s/iter; left time: 313.2013s\n",
      "Epoch: 2 cost time: 38.45885396003723\n",
      "Epoch: 2, Steps: 350 | Train Loss: 0.3155880 Vali Loss: 0.4358566 Test Loss: 0.5082778\n",
      "Validation loss decreased (0.436692 --> 0.435857).  Saving model ...\n",
      "Updating learning rate to 0.005\n",
      "\titers: 100, epoch: 3 | loss: 0.3049667\n",
      "\tspeed: 0.5312s/iter; left time: 1434.8603s\n",
      "\titers: 200, epoch: 3 | loss: 0.2885120\n",
      "\tspeed: 0.1083s/iter; left time: 281.5988s\n",
      "\titers: 300, epoch: 3 | loss: 0.2954009\n",
      "\tspeed: 0.1103s/iter; left time: 275.9071s\n",
      "Epoch: 3 cost time: 38.543477296829224\n",
      "Epoch: 3, Steps: 350 | Train Loss: 0.2973845 Vali Loss: 0.4187893 Test Loss: 0.4871589\n",
      "Validation loss decreased (0.435857 --> 0.418789).  Saving model ...\n",
      "Updating learning rate to 0.0025\n",
      "\titers: 100, epoch: 4 | loss: 0.2961706\n",
      "\tspeed: 0.5307s/iter; left time: 1247.5780s\n",
      "\titers: 200, epoch: 4 | loss: 0.2901939\n",
      "\tspeed: 0.1087s/iter; left time: 244.6243s\n",
      "\titers: 300, epoch: 4 | loss: 0.3090208\n",
      "\tspeed: 0.1097s/iter; left time: 235.9743s\n",
      "Epoch: 4 cost time: 38.61918354034424\n",
      "Epoch: 4, Steps: 350 | Train Loss: 0.2906513 Vali Loss: 0.4094255 Test Loss: 0.4732577\n",
      "Validation loss decreased (0.418789 --> 0.409426).  Saving model ...\n",
      "Updating learning rate to 0.00125\n",
      "\titers: 100, epoch: 5 | loss: 0.2886220\n",
      "\tspeed: 0.5326s/iter; left time: 1065.7473s\n",
      "\titers: 200, epoch: 5 | loss: 0.3100215\n",
      "\tspeed: 0.1083s/iter; left time: 205.8519s\n",
      "\titers: 300, epoch: 5 | loss: 0.2975785\n",
      "\tspeed: 0.1103s/iter; left time: 198.6277s\n",
      "Epoch: 5 cost time: 38.67703938484192\n",
      "Epoch: 5, Steps: 350 | Train Loss: 0.2871587 Vali Loss: 0.4064233 Test Loss: 0.4694990\n",
      "Validation loss decreased (0.409426 --> 0.406423).  Saving model ...\n",
      "Updating learning rate to 0.000625\n",
      "\titers: 100, epoch: 6 | loss: 0.2917349\n",
      "\tspeed: 0.5314s/iter; left time: 877.3023s\n",
      "\titers: 200, epoch: 6 | loss: 0.3004210\n",
      "\tspeed: 0.1087s/iter; left time: 168.5346s\n",
      "\titers: 300, epoch: 6 | loss: 0.2986602\n",
      "\tspeed: 0.1099s/iter; left time: 159.4586s\n",
      "Epoch: 6 cost time: 38.495307207107544\n",
      "Epoch: 6, Steps: 350 | Train Loss: 0.2853030 Vali Loss: 0.4044257 Test Loss: 0.4668207\n",
      "Validation loss decreased (0.406423 --> 0.404426).  Saving model ...\n",
      "Updating learning rate to 0.0003125\n",
      "\titers: 100, epoch: 7 | loss: 0.2855013\n",
      "\tspeed: 0.5298s/iter; left time: 689.2187s\n",
      "\titers: 200, epoch: 7 | loss: 0.2840915\n",
      "\tspeed: 0.1085s/iter; left time: 130.3633s\n",
      "\titers: 300, epoch: 7 | loss: 0.2828570\n",
      "\tspeed: 0.1099s/iter; left time: 121.0485s\n",
      "Epoch: 7 cost time: 38.55330181121826\n",
      "Epoch: 7, Steps: 350 | Train Loss: 0.2842547 Vali Loss: 0.4029638 Test Loss: 0.4635350\n",
      "Validation loss decreased (0.404426 --> 0.402964).  Saving model ...\n",
      "Updating learning rate to 0.00015625\n",
      "\titers: 100, epoch: 8 | loss: 0.2834687\n",
      "\tspeed: 0.5282s/iter; left time: 502.3011s\n",
      "\titers: 200, epoch: 8 | loss: 0.2871421\n",
      "\tspeed: 0.1043s/iter; left time: 88.7554s\n",
      "\titers: 300, epoch: 8 | loss: 0.2828386\n",
      "\tspeed: 0.1042s/iter; left time: 78.2649s\n",
      "Epoch: 8 cost time: 36.92693114280701\n",
      "Epoch: 8, Steps: 350 | Train Loss: 0.2836082 Vali Loss: 0.4030066 Test Loss: 0.4645305\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2829570\n",
      "\tspeed: 0.5239s/iter; left time: 314.8791s\n",
      "\titers: 200, epoch: 9 | loss: 0.2782675\n",
      "\tspeed: 0.1041s/iter; left time: 52.1317s\n",
      "\titers: 300, epoch: 9 | loss: 0.2725065\n",
      "\tspeed: 0.1049s/iter; left time: 42.0709s\n",
      "Epoch: 9 cost time: 37.02057242393494\n",
      "Epoch: 9, Steps: 350 | Train Loss: 0.2832720 Vali Loss: 0.4026528 Test Loss: 0.4638854\n",
      "Validation loss decreased (0.402964 --> 0.402653).  Saving model ...\n",
      "Updating learning rate to 3.90625e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2774239\n",
      "\tspeed: 0.5278s/iter; left time: 132.4801s\n",
      "\titers: 200, epoch: 10 | loss: 0.2755340\n",
      "\tspeed: 0.1093s/iter; left time: 16.4968s\n",
      "\titers: 300, epoch: 10 | loss: 0.2961440\n",
      "\tspeed: 0.1098s/iter; left time: 5.6015s\n",
      "Epoch: 10 cost time: 38.68247151374817\n",
      "Epoch: 10, Steps: 350 | Train Loss: 0.2830994 Vali Loss: 0.4018850 Test Loss: 0.4633672\n",
      "Validation loss decreased (0.402653 --> 0.401885).  Saving model ...\n",
      "Updating learning rate to 1.953125e-05\n",
      ">>>>>>>testing : Traffic_336_96_GLinear_custom_ftM_sl336_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2789\n",
      "mse:0.4629973769187927, mae:0.306870698928833\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Traffic_336_96_GLinear_custom_ftM_sl336_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 11225\n",
      "val 1037\n",
      "test 2789\n",
      "\titers: 100, epoch: 1 | loss: 0.3155383\n",
      "\tspeed: 0.1157s/iter; left time: 393.3607s\n",
      "\titers: 200, epoch: 1 | loss: 0.3010232\n",
      "\tspeed: 0.1107s/iter; left time: 365.5284s\n",
      "\titers: 300, epoch: 1 | loss: 0.3004072\n",
      "\tspeed: 0.1112s/iter; left time: 356.0913s\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/drive/MyDrive/MyProject_QMUL_Final/GLinear/run_longExp.py\", line 120, in <module>\n",
      "    exp.train(setting)\n",
      "  File \"/content/drive/MyDrive/MyProject_QMUL_Final/GLinear/exp/exp_main.py\", line 132, in train\n",
      "    batch_y = batch_y.float().to(self.device)\n",
      "              ^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python run_longExp.py \\\n",
    "  --is_training 1 \\\n",
    "  --model GLinear \\\n",
    "  --data custom \\\n",
    "  --root_path dataset/ \\\n",
    "  --data_path traffic.csv \\\n",
    "  --model_id Traffic_336_96 \\\n",
    "  --features M \\\n",
    "  --target OT \\\n",
    "  --seq_len 336 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 720 \\\n",
    "  --enc_in 862 \\\n",
    "  --dec_in 862 \\\n",
    "  --c_out 862 \\\n",
    "  --batch_size 32 \\\n",
    "  --learning_rate 0.01 \\\n",
    "  --use_gpu True \\\n",
    "  --gpu 0 \\\n",
    "  --des 'test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 103499,
     "status": "ok",
     "timestamp": 1747782942322,
     "user": {
      "displayName": "amali amali",
      "userId": "15718090331232743656"
     },
     "user_tz": -60
    },
    "id": "Yp92EVCW6vKw",
    "outputId": "cbdca375-13e8-4ac0-fba5-2f7b795de57d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Running: ETTh1, horizon=12\n",
      "Args in experiment:\n",
      "Namespace(is_training=1, train_only=False, model_id='ETTh1_12', model='GLinear', data='ETTh1', root_path='dataset/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='/spo/NewbornTime/tahir098/SVF/data/Extra/checkpoints/', seq_len=336, label_len=48, pred_len=12, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des='test', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ETTh1_12_GLinear_ETTh1_ftM_sl336_ll48_pl12_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8293\n",
      "val 2869\n",
      "test 2869\n",
      "\titers: 100, epoch: 1 | loss: 0.1916916\n",
      "\tspeed: 0.0218s/iter; left time: 54.2502s\n",
      "\titers: 200, epoch: 1 | loss: 0.2629096\n",
      "\tspeed: 0.0060s/iter; left time: 14.3521s\n",
      "Epoch: 1 cost time: 2.0374138355255127\n",
      "Epoch: 1, Steps: 259 | Train Loss: 0.2651515 Vali Loss: 0.3465505 Test Loss: 0.3113729\n",
      "Validation loss decreased (inf --> 0.346550).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "\titers: 100, epoch: 2 | loss: 0.1995058\n",
      "\tspeed: 0.0222s/iter; left time: 49.4701s\n",
      "\titers: 200, epoch: 2 | loss: 0.2083217\n",
      "\tspeed: 0.0062s/iter; left time: 13.2279s\n",
      "Epoch: 2 cost time: 1.7935044765472412\n",
      "Epoch: 2, Steps: 259 | Train Loss: 0.2037690 Vali Loss: 0.3277554 Test Loss: 0.2848931\n",
      "Validation loss decreased (0.346550 --> 0.327755).  Saving model ...\n",
      "Updating learning rate to 0.0005\n",
      "\titers: 100, epoch: 3 | loss: 0.1444523\n",
      "\tspeed: 0.0230s/iter; left time: 45.4050s\n",
      "\titers: 200, epoch: 3 | loss: 0.1435195\n",
      "\tspeed: 0.0063s/iter; left time: 11.8464s\n",
      "Epoch: 3 cost time: 1.8352386951446533\n",
      "Epoch: 3, Steps: 259 | Train Loss: 0.1639227 Vali Loss: 0.3356555 Test Loss: 0.2931848\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.00025\n",
      "\titers: 100, epoch: 4 | loss: 0.1271914\n",
      "\tspeed: 0.0227s/iter; left time: 38.8803s\n",
      "\titers: 200, epoch: 4 | loss: 0.1284113\n",
      "\tspeed: 0.0063s/iter; left time: 10.1445s\n",
      "Epoch: 4 cost time: 1.805849313735962\n",
      "Epoch: 4, Steps: 259 | Train Loss: 0.1372821 Vali Loss: 0.3386141 Test Loss: 0.3034878\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.000125\n",
      "\titers: 100, epoch: 5 | loss: 0.1095034\n",
      "\tspeed: 0.0221s/iter; left time: 32.1688s\n",
      "\titers: 200, epoch: 5 | loss: 0.1187099\n",
      "\tspeed: 0.0061s/iter; left time: 8.2391s\n",
      "Epoch: 5 cost time: 1.7614917755126953\n",
      "Epoch: 5, Steps: 259 | Train Loss: 0.1235311 Vali Loss: 0.3408766 Test Loss: 0.3008008\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh1_12_GLinear_ETTh1_ftM_sl336_ll48_pl12_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2869\n",
      "mse:0.28514063358306885, mae:0.3463129997253418\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ETTh1_12_GLinear_ETTh1_ftM_sl336_ll48_pl12_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8293\n",
      "val 2869\n",
      "test 2869\n",
      "\titers: 100, epoch: 1 | loss: 0.2090932\n",
      "\tspeed: 0.0080s/iter; left time: 19.9278s\n",
      "\titers: 200, epoch: 1 | loss: 0.2501454\n",
      "\tspeed: 0.0062s/iter; left time: 14.7881s\n",
      "Epoch: 1 cost time: 1.821889877319336\n",
      "Epoch: 1, Steps: 259 | Train Loss: 0.2625432 Vali Loss: 0.3420109 Test Loss: 0.3070586\n",
      "Validation loss decreased (inf --> 0.342011).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "\titers: 100, epoch: 2 | loss: 0.2102366\n",
      "\tspeed: 0.0238s/iter; left time: 53.1770s\n",
      "\titers: 200, epoch: 2 | loss: 0.2106098\n",
      "\tspeed: 0.0061s/iter; left time: 13.0477s\n",
      "Epoch: 2 cost time: 1.8266663551330566\n",
      "Epoch: 2, Steps: 259 | Train Loss: 0.2044857 Vali Loss: 0.3348232 Test Loss: 0.2959818\n",
      "Validation loss decreased (0.342011 --> 0.334823).  Saving model ...\n",
      "Updating learning rate to 0.0005\n",
      "\titers: 100, epoch: 3 | loss: 0.1688185\n",
      "\tspeed: 0.0236s/iter; left time: 46.6395s\n",
      "\titers: 200, epoch: 3 | loss: 0.1436418\n",
      "\tspeed: 0.0063s/iter; left time: 11.8620s\n",
      "Epoch: 3 cost time: 1.8369204998016357\n",
      "Epoch: 3, Steps: 259 | Train Loss: 0.1626324 Vali Loss: 0.3288661 Test Loss: 0.2941046\n",
      "Validation loss decreased (0.334823 --> 0.328866).  Saving model ...\n",
      "Updating learning rate to 0.00025\n",
      "\titers: 100, epoch: 4 | loss: 0.1195414\n",
      "\tspeed: 0.0233s/iter; left time: 39.8637s\n",
      "\titers: 200, epoch: 4 | loss: 0.1021284\n",
      "\tspeed: 0.0061s/iter; left time: 9.8104s\n",
      "Epoch: 4 cost time: 1.8290252685546875\n",
      "Epoch: 4, Steps: 259 | Train Loss: 0.1363580 Vali Loss: 0.3391999 Test Loss: 0.3103811\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.000125\n",
      "\titers: 100, epoch: 5 | loss: 0.1237266\n",
      "\tspeed: 0.0231s/iter; left time: 33.5649s\n",
      "\titers: 200, epoch: 5 | loss: 0.1020197\n",
      "\tspeed: 0.0061s/iter; left time: 8.2425s\n",
      "Epoch: 5 cost time: 1.8214714527130127\n",
      "Epoch: 5, Steps: 259 | Train Loss: 0.1228490 Vali Loss: 0.3394941 Test Loss: 0.3014711\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1257532\n",
      "\tspeed: 0.0236s/iter; left time: 28.2666s\n",
      "\titers: 200, epoch: 6 | loss: 0.1192978\n",
      "\tspeed: 0.0063s/iter; left time: 6.9555s\n",
      "Epoch: 6 cost time: 1.8226385116577148\n",
      "Epoch: 6, Steps: 259 | Train Loss: 0.1160532 Vali Loss: 0.3428194 Test Loss: 0.3117723\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh1_12_GLinear_ETTh1_ftM_sl336_ll48_pl12_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2869\n",
      "mse:0.2943575382232666, mae:0.3463287055492401\n",
      ">>> Running: ETTh2, horizon=12\n",
      "Args in experiment:\n",
      "Namespace(is_training=1, train_only=False, model_id='ETTh2_12', model='GLinear', data='ETTh2', root_path='dataset/', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='/spo/NewbornTime/tahir098/SVF/data/Extra/checkpoints/', seq_len=336, label_len=48, pred_len=12, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des='test', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ETTh2_12_GLinear_ETTh2_ftM_sl336_ll48_pl12_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8293\n",
      "val 2869\n",
      "test 2869\n",
      "\titers: 100, epoch: 1 | loss: 0.1935536\n",
      "\tspeed: 0.0217s/iter; left time: 54.1471s\n",
      "\titers: 200, epoch: 1 | loss: 0.1368949\n",
      "\tspeed: 0.0063s/iter; left time: 14.9949s\n",
      "Epoch: 1 cost time: 2.063755512237549\n",
      "Epoch: 1, Steps: 259 | Train Loss: 0.2068516 Vali Loss: 0.1099276 Test Loss: 0.1528613\n",
      "Validation loss decreased (inf --> 0.109928).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "\titers: 100, epoch: 2 | loss: 0.1318753\n",
      "\tspeed: 0.0228s/iter; left time: 50.8390s\n",
      "\titers: 200, epoch: 2 | loss: 0.1363242\n",
      "\tspeed: 0.0059s/iter; left time: 12.6390s\n",
      "Epoch: 2 cost time: 1.798067569732666\n",
      "Epoch: 2, Steps: 259 | Train Loss: 0.1531401 Vali Loss: 0.1024193 Test Loss: 0.1399214\n",
      "Validation loss decreased (0.109928 --> 0.102419).  Saving model ...\n",
      "Updating learning rate to 0.0005\n",
      "\titers: 100, epoch: 3 | loss: 0.1031971\n",
      "\tspeed: 0.0222s/iter; left time: 43.8133s\n",
      "\titers: 200, epoch: 3 | loss: 0.1167949\n",
      "\tspeed: 0.0061s/iter; left time: 11.4113s\n",
      "Epoch: 3 cost time: 1.7712748050689697\n",
      "Epoch: 3, Steps: 259 | Train Loss: 0.1244864 Vali Loss: 0.1016024 Test Loss: 0.1385359\n",
      "Validation loss decreased (0.102419 --> 0.101602).  Saving model ...\n",
      "Updating learning rate to 0.00025\n",
      "\titers: 100, epoch: 4 | loss: 0.1745762\n",
      "\tspeed: 0.0221s/iter; left time: 37.8099s\n",
      "\titers: 200, epoch: 4 | loss: 0.0826810\n",
      "\tspeed: 0.0062s/iter; left time: 9.9422s\n",
      "Epoch: 4 cost time: 1.780700922012329\n",
      "Epoch: 4, Steps: 259 | Train Loss: 0.1083353 Vali Loss: 0.1033075 Test Loss: 0.1397946\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.000125\n",
      "\titers: 100, epoch: 5 | loss: 0.1199210\n",
      "\tspeed: 0.0219s/iter; left time: 31.8764s\n",
      "\titers: 200, epoch: 5 | loss: 0.1165307\n",
      "\tspeed: 0.0062s/iter; left time: 8.4537s\n",
      "Epoch: 5 cost time: 1.793576955795288\n",
      "Epoch: 5, Steps: 259 | Train Loss: 0.0993179 Vali Loss: 0.1039015 Test Loss: 0.1408492\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0821961\n",
      "\tspeed: 0.0226s/iter; left time: 27.0748s\n",
      "\titers: 200, epoch: 6 | loss: 0.0945607\n",
      "\tspeed: 0.0065s/iter; left time: 7.1141s\n",
      "Epoch: 6 cost time: 1.8201079368591309\n",
      "Epoch: 6, Steps: 259 | Train Loss: 0.0948442 Vali Loss: 0.1046597 Test Loss: 0.1419921\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh2_12_GLinear_ETTh2_ftM_sl336_ll48_pl12_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2869\n",
      "mse:0.13857078552246094, mae:0.24379870295524597\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ETTh2_12_GLinear_ETTh2_ftM_sl336_ll48_pl12_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8293\n",
      "val 2869\n",
      "test 2869\n",
      "\titers: 100, epoch: 1 | loss: 0.1529350\n",
      "\tspeed: 0.0082s/iter; left time: 20.4978s\n",
      "\titers: 200, epoch: 1 | loss: 0.0953681\n",
      "\tspeed: 0.0062s/iter; left time: 14.7121s\n",
      "Epoch: 1 cost time: 1.8452732563018799\n",
      "Epoch: 1, Steps: 259 | Train Loss: 0.2094671 Vali Loss: 0.1071327 Test Loss: 0.1476105\n",
      "Validation loss decreased (inf --> 0.107133).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "\titers: 100, epoch: 2 | loss: 0.3204921\n",
      "\tspeed: 0.0228s/iter; left time: 50.8785s\n",
      "\titers: 200, epoch: 2 | loss: 0.1573735\n",
      "\tspeed: 0.0060s/iter; left time: 12.8793s\n",
      "Epoch: 2 cost time: 1.7767407894134521\n",
      "Epoch: 2, Steps: 259 | Train Loss: 0.1526406 Vali Loss: 0.1054802 Test Loss: 0.1452208\n",
      "Validation loss decreased (0.107133 --> 0.105480).  Saving model ...\n",
      "Updating learning rate to 0.0005\n",
      "\titers: 100, epoch: 3 | loss: 0.1679927\n",
      "\tspeed: 0.0232s/iter; left time: 45.8146s\n",
      "\titers: 200, epoch: 3 | loss: 0.1603276\n",
      "\tspeed: 0.0062s/iter; left time: 11.6836s\n",
      "Epoch: 3 cost time: 1.8713815212249756\n",
      "Epoch: 3, Steps: 259 | Train Loss: 0.1230519 Vali Loss: 0.1015498 Test Loss: 0.1421137\n",
      "Validation loss decreased (0.105480 --> 0.101550).  Saving model ...\n",
      "Updating learning rate to 0.00025\n",
      "\titers: 100, epoch: 4 | loss: 0.0654906\n",
      "\tspeed: 0.0239s/iter; left time: 40.9455s\n",
      "\titers: 200, epoch: 4 | loss: 0.0656555\n",
      "\tspeed: 0.0062s/iter; left time: 9.9988s\n",
      "Epoch: 4 cost time: 1.833099126815796\n",
      "Epoch: 4, Steps: 259 | Train Loss: 0.1079481 Vali Loss: 0.1013096 Test Loss: 0.1380241\n",
      "Validation loss decreased (0.101550 --> 0.101310).  Saving model ...\n",
      "Updating learning rate to 0.000125\n",
      "\titers: 100, epoch: 5 | loss: 0.1010914\n",
      "\tspeed: 0.0229s/iter; left time: 33.3462s\n",
      "\titers: 200, epoch: 5 | loss: 0.0640029\n",
      "\tspeed: 0.0060s/iter; left time: 8.1970s\n",
      "Epoch: 5 cost time: 1.7853002548217773\n",
      "Epoch: 5, Steps: 259 | Train Loss: 0.0998784 Vali Loss: 0.1038406 Test Loss: 0.1413416\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0798246\n",
      "\tspeed: 0.0229s/iter; left time: 27.3690s\n",
      "\titers: 200, epoch: 6 | loss: 0.1348909\n",
      "\tspeed: 0.0061s/iter; left time: 6.7109s\n",
      "Epoch: 6 cost time: 1.8037898540496826\n",
      "Epoch: 6, Steps: 259 | Train Loss: 0.0955768 Vali Loss: 0.1026884 Test Loss: 0.1403732\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0757521\n",
      "\tspeed: 0.0233s/iter; left time: 21.8764s\n",
      "\titers: 200, epoch: 7 | loss: 0.1428824\n",
      "\tspeed: 0.0061s/iter; left time: 5.0785s\n",
      "Epoch: 7 cost time: 1.827749490737915\n",
      "Epoch: 7, Steps: 259 | Train Loss: 0.0933032 Vali Loss: 0.1040523 Test Loss: 0.1413163\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh2_12_GLinear_ETTh2_ftM_sl336_ll48_pl12_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2869\n",
      "mse:0.13815516233444214, mae:0.24084830284118652\n",
      ">>> Running: Electricity, horizon=12\n",
      "Args in experiment:\n",
      "Namespace(is_training=1, train_only=False, model_id='Electricity_12', model='GLinear', data='Electricity', root_path='dataset/', data_path='electricity.csv', features='M', target='OT', freq='h', checkpoints='/spo/NewbornTime/tahir098/SVF/data/Extra/checkpoints/', seq_len=336, label_len=48, pred_len=12, individual=False, embed_type=0, enc_in=321, dec_in=321, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des='test', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Electricity_12_GLinear_Electricity_ftM_sl336_ll48_pl12_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/drive/MyDrive/MyProject_QMUL_Final/GLinear/run_longExp.py\", line 120, in <module>\n",
      "    exp.train(setting)\n",
      "  File \"/content/drive/MyDrive/MyProject_QMUL_Final/GLinear/exp/exp_main.py\", line 101, in train\n",
      "    train_data, train_loader = self._get_data(flag='train')\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/content/drive/MyDrive/MyProject_QMUL_Final/GLinear/exp/exp_main.py\", line 43, in _get_data\n",
      "    data_set, data_loader = data_provider(self.args, flag)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/content/drive/MyDrive/MyProject_QMUL_Final/GLinear/data_provider/data_factory.py\", line 15, in data_provider\n",
      "    Data = data_dict[args.data]\n",
      "           ~~~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'Electricity'\n",
      ">>> Running: Weather, horizon=12\n",
      "Args in experiment:\n",
      "Namespace(is_training=1, train_only=False, model_id='Weather_12', model='GLinear', data='Weather', root_path='dataset/', data_path='weather.csv', features='M', target='OT', freq='h', checkpoints='/spo/NewbornTime/tahir098/SVF/data/Extra/checkpoints/', seq_len=336, label_len=48, pred_len=12, individual=False, embed_type=0, enc_in=21, dec_in=21, c_out=21, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des='test', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Weather_12_GLinear_Weather_ftM_sl336_ll48_pl12_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/drive/MyDrive/MyProject_QMUL_Final/GLinear/run_longExp.py\", line 120, in <module>\n",
      "    exp.train(setting)\n",
      "  File \"/content/drive/MyDrive/MyProject_QMUL_Final/GLinear/exp/exp_main.py\", line 101, in train\n",
      "    train_data, train_loader = self._get_data(flag='train')\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/content/drive/MyDrive/MyProject_QMUL_Final/GLinear/exp/exp_main.py\", line 43, in _get_data\n",
      "    data_set, data_loader = data_provider(self.args, flag)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/content/drive/MyDrive/MyProject_QMUL_Final/GLinear/data_provider/data_factory.py\", line 15, in data_provider\n",
      "    Data = data_dict[args.data]\n",
      "           ~~~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'Weather'\n",
      ">>> Running: Traffic, horizon=12\n",
      "Args in experiment:\n",
      "Namespace(is_training=1, train_only=False, model_id='Traffic_12', model='GLinear', data='Traffic', root_path='dataset/', data_path='traffic.csv', features='M', target='OT', freq='h', checkpoints='/spo/NewbornTime/tahir098/SVF/data/Extra/checkpoints/', seq_len=336, label_len=48, pred_len=12, individual=False, embed_type=0, enc_in=862, dec_in=862, c_out=862, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des='test', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Traffic_12_GLinear_Traffic_ftM_sl336_ll48_pl12_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/drive/MyDrive/MyProject_QMUL_Final/GLinear/run_longExp.py\", line 120, in <module>\n",
      "    exp.train(setting)\n",
      "  File \"/content/drive/MyDrive/MyProject_QMUL_Final/GLinear/exp/exp_main.py\", line 101, in train\n",
      "    train_data, train_loader = self._get_data(flag='train')\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/content/drive/MyDrive/MyProject_QMUL_Final/GLinear/exp/exp_main.py\", line 43, in _get_data\n",
      "    data_set, data_loader = data_provider(self.args, flag)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/content/drive/MyDrive/MyProject_QMUL_Final/GLinear/data_provider/data_factory.py\", line 15, in data_provider\n",
      "    Data = data_dict[args.data]\n",
      "           ~~~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'Traffic'\n",
      ">>> Running: ExchangeRate, horizon=12\n",
      "Args in experiment:\n",
      "Namespace(is_training=1, train_only=False, model_id='ExchangeRate_12', model='GLinear', data='ExchangeRate', root_path='dataset/', data_path='exchange_rate.csv', features='M', target='OT', freq='h', checkpoints='/spo/NewbornTime/tahir098/SVF/data/Extra/checkpoints/', seq_len=336, label_len=48, pred_len=12, individual=False, embed_type=0, enc_in=8, dec_in=8, c_out=8, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des='test', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ExchangeRate_12_GLinear_ExchangeRate_ftM_sl336_ll48_pl12_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/drive/MyDrive/MyProject_QMUL_Final/GLinear/run_longExp.py\", line 120, in <module>\n",
      "    exp.train(setting)\n",
      "  File \"/content/drive/MyDrive/MyProject_QMUL_Final/GLinear/exp/exp_main.py\", line 101, in train\n",
      "    train_data, train_loader = self._get_data(flag='train')\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/content/drive/MyDrive/MyProject_QMUL_Final/GLinear/exp/exp_main.py\", line 43, in _get_data\n",
      "    data_set, data_loader = data_provider(self.args, flag)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/content/drive/MyDrive/MyProject_QMUL_Final/GLinear/data_provider/data_factory.py\", line 15, in data_provider\n",
      "    Data = data_dict[args.data]\n",
      "           ~~~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'ExchangeRate'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "datasets = {\n",
    "    'ETTh1': 'ETTh1.csv',\n",
    "    'ETTh2': 'ETTh2.csv',\n",
    "    'Electricity': 'electricity.csv',\n",
    "    'Weather': 'weather.csv',\n",
    "    'Traffic': 'traffic.csv',\n",
    "    'ExchangeRate': 'exchange_rate.csv',\n",
    "}\n",
    "\n",
    "pred_lens = [12 ]\n",
    "#pred_lens = [12, 24, 48, 96, 192, 336, 720]\n",
    "\n",
    "for data_name, data_file in datasets.items():\n",
    "    # Infer enc_in based on dataset\n",
    "    if data_name == 'ETTh1' or data_name == 'ETTh2':\n",
    "        enc_in = 7\n",
    "    elif data_name == 'Electricity':\n",
    "        enc_in = 321\n",
    "    elif data_name == 'Traffic':\n",
    "        enc_in = 862\n",
    "    elif data_name == 'Weather':\n",
    "        enc_in = 21\n",
    "    elif data_name == 'ExchangeRate':\n",
    "        enc_in = 8  # or use df.shape[1] from exchange_rate.csv\n",
    "    else:\n",
    "        enc_in = 1\n",
    "\n",
    "    for pred_len in pred_lens:\n",
    "        print(f\">>> Running: {data_name}, horizon={pred_len}\")\n",
    "        cmd = (\n",
    "            f\"python run_longExp.py --is_training 1 --model GLinear \"\n",
    "            f\"--data {data_name} --root_path dataset/ --data_path {data_file} \"\n",
    "            f\"--model_id {data_name}_{pred_len} --seq_len 336 --label_len 48 \"\n",
    "            f\"--pred_len {pred_len} --features M --target OT \"\n",
    "            f\"--enc_in {enc_in} --dec_in {enc_in} --c_out {enc_in} \"\n",
    "            f\"--learning_rate 0.001 --batch_size 32 --train_epochs 10 \"\n",
    "            f\"--use_gpu True --gpu 0\"\n",
    "        )\n",
    "        # Use !{cmd} to see live output in Colab\n",
    "        !{cmd}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "nwBhbpUhdlMl"
   },
   "outputs": [],
   "source": [
    "!python run_longExp.py \\\n",
    "  --is_training 1 \\\n",
    "  --model GLinear \\\n",
    "  --data custom \\\n",
    "  --root_path dataset/ \\\n",
    "  --data_path weather.csv \\\n",
    "  --model_id Weather_336_96 \\\n",
    "  --features M \\\n",
    "  --target OT \\\n",
    "  --seq_len 336 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 720 \\\n",
    "  --enc_in 21 \\\n",
    "  --dec_in 21 \\\n",
    "  --c_out 21 \\\n",
    "  --batch_size 32 \\\n",
    "  --learning_rate 0.001 \\\n",
    "  --use_gpu True \\\n",
    "  --gpu 0 \\\n",
    "  --des 'test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 248086,
     "status": "ok",
     "timestamp": 1747908442336,
     "user": {
      "displayName": "amali amali",
      "userId": "15718090331232743656"
     },
     "user_tz": -60
    },
    "id": "xFJq3jkTC67C",
    "outputId": "471771ae-c293-4034-9233-b3c124bc017e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/MyProject_QMUL_Final/GLinear\n",
      "Current directory: /content/drive/MyDrive/MyProject_QMUL_Final/GLinear\n",
      "Args in experiment:\n",
      "Namespace(is_training=1, train_only=False, model_id='Weather_336_96', model='GLinear', data='custom', root_path='dataset/', data_path='weather.csv', features='M', target='OT', freq='h', checkpoints='/spo/NewbornTime/tahir098/SVF/data/Extra/checkpoints/', seq_len=336, label_len=48, pred_len=720, individual=False, embed_type=0, enc_in=21, dec_in=21, c_out=21, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des='test', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Weather_336_96_GLinear_custom_ftM_sl336_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 35832\n",
      "val 4551\n",
      "test 9820\n",
      "\titers: 100, epoch: 1 | loss: 0.5565172\n",
      "\tspeed: 0.0249s/iter; left time: 276.4578s\n",
      "\titers: 200, epoch: 1 | loss: 0.5780591\n",
      "\tspeed: 0.0087s/iter; left time: 95.6785s\n",
      "\titers: 300, epoch: 1 | loss: 0.5624498\n",
      "\tspeed: 0.0087s/iter; left time: 94.8368s\n",
      "\titers: 400, epoch: 1 | loss: 0.4766084\n",
      "\tspeed: 0.0087s/iter; left time: 93.9762s\n",
      "\titers: 500, epoch: 1 | loss: 0.5853996\n",
      "\tspeed: 0.0088s/iter; left time: 93.5633s\n",
      "\titers: 600, epoch: 1 | loss: 0.5461180\n",
      "\tspeed: 0.0088s/iter; left time: 93.0023s\n",
      "\titers: 700, epoch: 1 | loss: 0.5694785\n",
      "\tspeed: 0.0087s/iter; left time: 91.3871s\n",
      "\titers: 800, epoch: 1 | loss: 0.6864701\n",
      "\tspeed: 0.0087s/iter; left time: 90.6944s\n",
      "\titers: 900, epoch: 1 | loss: 0.7195141\n",
      "\tspeed: 0.0086s/iter; left time: 88.9520s\n",
      "\titers: 1000, epoch: 1 | loss: 0.5434460\n",
      "\tspeed: 0.0090s/iter; left time: 91.7533s\n",
      "\titers: 1100, epoch: 1 | loss: 0.6531642\n",
      "\tspeed: 0.0089s/iter; left time: 89.3961s\n",
      "Epoch: 1 cost time: 10.307053565979004\n",
      "Epoch: 1, Steps: 1119 | Train Loss: 0.6177306 Vali Loss: 0.6410412 Test Loss: 0.3253309\n",
      "Validation loss decreased (inf --> 0.641041).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "\titers: 100, epoch: 2 | loss: 0.8160676\n",
      "\tspeed: 0.0669s/iter; left time: 666.7850s\n",
      "\titers: 200, epoch: 2 | loss: 0.5790133\n",
      "\tspeed: 0.0086s/iter; left time: 84.5013s\n",
      "\titers: 300, epoch: 2 | loss: 0.6367331\n",
      "\tspeed: 0.0088s/iter; left time: 85.8737s\n",
      "\titers: 400, epoch: 2 | loss: 0.7514124\n",
      "\tspeed: 0.0088s/iter; left time: 85.5905s\n",
      "\titers: 500, epoch: 2 | loss: 0.5791545\n",
      "\tspeed: 0.0090s/iter; left time: 85.7492s\n",
      "\titers: 600, epoch: 2 | loss: 0.6269876\n",
      "\tspeed: 0.0090s/iter; left time: 84.8328s\n",
      "\titers: 700, epoch: 2 | loss: 0.5391797\n",
      "\tspeed: 0.0091s/iter; left time: 85.5542s\n",
      "\titers: 800, epoch: 2 | loss: 1.0997764\n",
      "\tspeed: 0.0092s/iter; left time: 85.4577s\n",
      "\titers: 900, epoch: 2 | loss: 0.5633959\n",
      "\tspeed: 0.0091s/iter; left time: 83.4998s\n",
      "\titers: 1000, epoch: 2 | loss: 0.4769810\n",
      "\tspeed: 0.0090s/iter; left time: 82.0273s\n",
      "\titers: 1100, epoch: 2 | loss: 0.4671094\n",
      "\tspeed: 0.0092s/iter; left time: 82.6281s\n",
      "Epoch: 2 cost time: 10.425447940826416\n",
      "Epoch: 2, Steps: 1119 | Train Loss: 0.5649459 Vali Loss: 0.6666247 Test Loss: 0.3393632\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0005\n",
      "\titers: 100, epoch: 3 | loss: 0.5388978\n",
      "\tspeed: 0.0882s/iter; left time: 780.5396s\n",
      "\titers: 200, epoch: 3 | loss: 0.4169258\n",
      "\tspeed: 0.0091s/iter; left time: 79.9889s\n",
      "\titers: 300, epoch: 3 | loss: 0.6195765\n",
      "\tspeed: 0.0088s/iter; left time: 76.4371s\n",
      "\titers: 400, epoch: 3 | loss: 0.4110274\n",
      "\tspeed: 0.0088s/iter; left time: 75.0591s\n",
      "\titers: 500, epoch: 3 | loss: 0.4352743\n",
      "\tspeed: 0.0088s/iter; left time: 74.4730s\n",
      "\titers: 600, epoch: 3 | loss: 0.5007069\n",
      "\tspeed: 0.0088s/iter; left time: 73.2886s\n",
      "\titers: 700, epoch: 3 | loss: 0.5347974\n",
      "\tspeed: 0.0088s/iter; left time: 72.6171s\n",
      "\titers: 800, epoch: 3 | loss: 0.4342003\n",
      "\tspeed: 0.0085s/iter; left time: 69.6482s\n",
      "\titers: 900, epoch: 3 | loss: 0.4707245\n",
      "\tspeed: 0.0086s/iter; left time: 69.3016s\n",
      "\titers: 1000, epoch: 3 | loss: 0.4408976\n",
      "\tspeed: 0.0087s/iter; left time: 69.1188s\n",
      "\titers: 1100, epoch: 3 | loss: 0.4767374\n",
      "\tspeed: 0.0087s/iter; left time: 67.9688s\n",
      "Epoch: 3 cost time: 10.243967533111572\n",
      "Epoch: 3, Steps: 1119 | Train Loss: 0.5151144 Vali Loss: 0.6760020 Test Loss: 0.3514184\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.00025\n",
      "\titers: 100, epoch: 4 | loss: 0.6336214\n",
      "\tspeed: 0.0874s/iter; left time: 675.8196s\n",
      "\titers: 200, epoch: 4 | loss: 0.3963080\n",
      "\tspeed: 0.0086s/iter; left time: 65.4913s\n",
      "\titers: 300, epoch: 4 | loss: 0.4329319\n",
      "\tspeed: 0.0087s/iter; left time: 65.7227s\n",
      "\titers: 400, epoch: 4 | loss: 0.4125491\n",
      "\tspeed: 0.0089s/iter; left time: 66.1318s\n",
      "\titers: 500, epoch: 4 | loss: 0.4013952\n",
      "\tspeed: 0.0084s/iter; left time: 61.8268s\n",
      "\titers: 600, epoch: 4 | loss: 0.4757655\n",
      "\tspeed: 0.0087s/iter; left time: 62.7770s\n",
      "\titers: 700, epoch: 4 | loss: 0.5384559\n",
      "\tspeed: 0.0090s/iter; left time: 64.4845s\n",
      "\titers: 800, epoch: 4 | loss: 0.5741772\n",
      "\tspeed: 0.0089s/iter; left time: 62.8464s\n",
      "\titers: 900, epoch: 4 | loss: 0.3428833\n",
      "\tspeed: 0.0090s/iter; left time: 62.5043s\n",
      "\titers: 1000, epoch: 4 | loss: 0.4918193\n",
      "\tspeed: 0.0094s/iter; left time: 64.3744s\n",
      "\titers: 1100, epoch: 4 | loss: 0.4903416\n",
      "\tspeed: 0.0091s/iter; left time: 61.2990s\n",
      "Epoch: 4 cost time: 10.293932914733887\n",
      "Epoch: 4, Steps: 1119 | Train Loss: 0.4893022 Vali Loss: 0.6821612 Test Loss: 0.3552624\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : Weather_336_96_GLinear_custom_ftM_sl336_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 9820\n",
      "mse:0.3252653181552887, mae:0.3354891836643219\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Weather_336_96_GLinear_custom_ftM_sl336_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 35832\n",
      "val 4551\n",
      "test 9820\n",
      "\titers: 100, epoch: 1 | loss: 0.6734757\n",
      "\tspeed: 0.0128s/iter; left time: 141.8464s\n",
      "\titers: 200, epoch: 1 | loss: 0.9360065\n",
      "\tspeed: 0.0089s/iter; left time: 97.7625s\n",
      "\titers: 300, epoch: 1 | loss: 0.5457950\n",
      "\tspeed: 0.0088s/iter; left time: 95.4330s\n",
      "\titers: 400, epoch: 1 | loss: 0.6815245\n",
      "\tspeed: 0.0090s/iter; left time: 96.7338s\n",
      "\titers: 500, epoch: 1 | loss: 0.5397546\n",
      "\tspeed: 0.0087s/iter; left time: 93.1898s\n",
      "\titers: 600, epoch: 1 | loss: 0.8932949\n",
      "\tspeed: 0.0090s/iter; left time: 94.8915s\n",
      "\titers: 700, epoch: 1 | loss: 0.5461154\n",
      "\tspeed: 0.0093s/iter; left time: 97.2679s\n",
      "\titers: 800, epoch: 1 | loss: 0.5031441\n",
      "\tspeed: 0.0094s/iter; left time: 98.1055s\n",
      "\titers: 900, epoch: 1 | loss: 0.6045617\n",
      "\tspeed: 0.0092s/iter; left time: 95.1306s\n",
      "\titers: 1000, epoch: 1 | loss: 0.4911633\n",
      "\tspeed: 0.0095s/iter; left time: 96.8770s\n",
      "\titers: 1100, epoch: 1 | loss: 0.4341619\n",
      "\tspeed: 0.0090s/iter; left time: 90.6699s\n",
      "Epoch: 1 cost time: 10.592029333114624\n",
      "Epoch: 1, Steps: 1119 | Train Loss: 0.6182329 Vali Loss: 0.6516052 Test Loss: 0.3242058\n",
      "Validation loss decreased (inf --> 0.651605).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "\titers: 100, epoch: 2 | loss: 0.5728440\n",
      "\tspeed: 0.2072s/iter; left time: 2066.3353s\n",
      "\titers: 200, epoch: 2 | loss: 0.4364993\n",
      "\tspeed: 0.0093s/iter; left time: 92.2344s\n",
      "\titers: 300, epoch: 2 | loss: 0.5184475\n",
      "\tspeed: 0.0095s/iter; left time: 92.6605s\n",
      "\titers: 400, epoch: 2 | loss: 0.6122259\n",
      "\tspeed: 0.0096s/iter; left time: 92.3691s\n",
      "\titers: 500, epoch: 2 | loss: 0.7294171\n",
      "\tspeed: 0.0091s/iter; left time: 86.6591s\n",
      "\titers: 600, epoch: 2 | loss: 0.6324362\n",
      "\tspeed: 0.0090s/iter; left time: 85.5594s\n",
      "\titers: 700, epoch: 2 | loss: 0.4494534\n",
      "\tspeed: 0.0092s/iter; left time: 86.1500s\n",
      "\titers: 800, epoch: 2 | loss: 0.3973796\n",
      "\tspeed: 0.0091s/iter; left time: 84.7873s\n",
      "\titers: 900, epoch: 2 | loss: 0.5674376\n",
      "\tspeed: 0.0089s/iter; left time: 81.9374s\n",
      "\titers: 1000, epoch: 2 | loss: 0.4802498\n",
      "\tspeed: 0.0088s/iter; left time: 79.7172s\n",
      "\titers: 1100, epoch: 2 | loss: 0.7360961\n",
      "\tspeed: 0.0090s/iter; left time: 80.9004s\n",
      "Epoch: 2 cost time: 10.777933120727539\n",
      "Epoch: 2, Steps: 1119 | Train Loss: 0.5633484 Vali Loss: 0.6626436 Test Loss: 0.3431453\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0005\n",
      "\titers: 100, epoch: 3 | loss: 0.6607420\n",
      "\tspeed: 0.0993s/iter; left time: 878.7585s\n",
      "\titers: 200, epoch: 3 | loss: 0.5371566\n",
      "\tspeed: 0.0091s/iter; left time: 79.4974s\n",
      "\titers: 300, epoch: 3 | loss: 0.5435997\n",
      "\tspeed: 0.0090s/iter; left time: 77.4998s\n",
      "\titers: 400, epoch: 3 | loss: 0.3929189\n",
      "\tspeed: 0.0089s/iter; left time: 76.4453s\n",
      "\titers: 500, epoch: 3 | loss: 0.4675784\n",
      "\tspeed: 0.0091s/iter; left time: 77.1705s\n",
      "\titers: 600, epoch: 3 | loss: 0.4825057\n",
      "\tspeed: 0.0091s/iter; left time: 75.7915s\n",
      "\titers: 700, epoch: 3 | loss: 0.5980354\n",
      "\tspeed: 0.0089s/iter; left time: 73.8304s\n",
      "\titers: 800, epoch: 3 | loss: 0.5615594\n",
      "\tspeed: 0.0090s/iter; left time: 73.6783s\n",
      "\titers: 900, epoch: 3 | loss: 0.6845934\n",
      "\tspeed: 0.0089s/iter; left time: 71.8992s\n",
      "\titers: 1000, epoch: 3 | loss: 0.4145628\n",
      "\tspeed: 0.0093s/iter; left time: 74.2557s\n",
      "\titers: 1100, epoch: 3 | loss: 0.4398077\n",
      "\tspeed: 0.0091s/iter; left time: 71.2076s\n",
      "Epoch: 3 cost time: 10.618972778320312\n",
      "Epoch: 3, Steps: 1119 | Train Loss: 0.5121988 Vali Loss: 0.6745036 Test Loss: 0.3500241\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.00025\n",
      "\titers: 100, epoch: 4 | loss: 0.4267928\n",
      "\tspeed: 0.0985s/iter; left time: 761.6126s\n",
      "\titers: 200, epoch: 4 | loss: 0.5842496\n",
      "\tspeed: 0.0092s/iter; left time: 70.5818s\n",
      "\titers: 300, epoch: 4 | loss: 0.5839837\n",
      "\tspeed: 0.0094s/iter; left time: 71.0285s\n",
      "\titers: 400, epoch: 4 | loss: 0.5326871\n",
      "\tspeed: 0.0088s/iter; left time: 65.7698s\n",
      "\titers: 500, epoch: 4 | loss: 0.4453040\n",
      "\tspeed: 0.0089s/iter; left time: 65.2338s\n",
      "\titers: 600, epoch: 4 | loss: 0.3898339\n",
      "\tspeed: 0.0092s/iter; left time: 66.4589s\n",
      "\titers: 700, epoch: 4 | loss: 0.5760174\n",
      "\tspeed: 0.0090s/iter; left time: 64.0704s\n",
      "\titers: 800, epoch: 4 | loss: 0.5262055\n",
      "\tspeed: 0.0089s/iter; left time: 62.2871s\n",
      "\titers: 900, epoch: 4 | loss: 0.5775509\n",
      "\tspeed: 0.0087s/iter; left time: 60.2824s\n",
      "\titers: 1000, epoch: 4 | loss: 0.7738776\n",
      "\tspeed: 0.0089s/iter; left time: 60.6208s\n",
      "\titers: 1100, epoch: 4 | loss: 0.4285955\n",
      "\tspeed: 0.0088s/iter; left time: 59.5056s\n",
      "Epoch: 4 cost time: 10.572130918502808\n",
      "Epoch: 4, Steps: 1119 | Train Loss: 0.4865705 Vali Loss: 0.6820465 Test Loss: 0.3594932\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : Weather_336_96_GLinear_custom_ftM_sl336_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 9820\n",
      "mse:0.3241455852985382, mae:0.3358917534351349\n",
      "\n",
      "ðŸ“ Saved experiments:\n",
      "exp_basic.py  exp_main.py  exp_stat.py\t__pycache__\n"
     ]
    }
   ],
   "source": [
    "# new Residual Stacked GLinear Model name remains \"GLinear\"\n",
    "%cd /content/drive/MyDrive/MyProject_QMUL_Final/GLinear\n",
    "\n",
    "# Confirming working directory\n",
    "import os\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "\n",
    "# Run training with unique parameter spec for each data set\n",
    "!python run_longExp.py \\\n",
    "  --is_training 1 \\\n",
    "  --model GLinear \\\n",
    "  --data custom \\\n",
    "  --root_path dataset/ \\\n",
    "  --data_path weather.csv \\\n",
    "  --model_id Weather_336_96 \\\n",
    "  --features M \\\n",
    "  --target OT \\\n",
    "  --seq_len 336 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 720 \\\n",
    "  --enc_in 21 \\\n",
    "  --dec_in 21 \\\n",
    "  --c_out 21 \\\n",
    "  --batch_size 32 \\\n",
    "  --learning_rate 0.001 \\\n",
    "  --use_gpu True \\\n",
    "  --gpu 0 \\\n",
    "  --des 'test'\n",
    "\n",
    "\n",
    "# Step 4: Show saved experiment results\n",
    "print(\"\\nðŸ“ Saved experiments:\")\n",
    "!ls ./exp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "af00XCZSD2bW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68024,
     "status": "ok",
     "timestamp": 1748774744917,
     "user": {
      "displayName": "amali amali",
      "userId": "15718090331232743656"
     },
     "user_tz": -60
    },
    "id": "qhFxxpRaaIwt",
    "outputId": "a6abf8da-8480-4482-cf1a-b91de6c4f543"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/MyProject_QMUL_Final/GLinear\n",
      "Current directory: /content/drive/MyDrive/MyProject_QMUL_Final/GLinear\n",
      "Args in experiment:\n",
      "Namespace(is_training=1, train_only=False, model_id='Exchange_336_1day', model='GLinear', data='custom', root_path='dataset/', data_path='exchange_rate.csv', features='M', target='OT', freq='h', checkpoints='/spo/NewbornTime/tahir098/SVF/data/Extra/checkpoints/', seq_len=1000, label_len=48, pred_len=336, individual=False, embed_type=0, enc_in=8, dec_in=8, c_out=8, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=1e-05, des='test', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Exchange_336_1day_GLinear_custom_ftM_sl1000_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 3976\n",
      "val 425\n",
      "test 1182\n",
      "\titers: 100, epoch: 1 | loss: 0.5623456\n",
      "\tspeed: 0.0709s/iter; left time: 80.9176s\n",
      "Epoch: 1 cost time: 2.735396146774292\n",
      "Epoch: 1, Steps: 124 | Train Loss: 0.8687164 Vali Loss: 0.7604786 Test Loss: 0.5545260\n",
      "Validation loss decreased (inf --> 0.760479).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.4769909\n",
      "\tspeed: 0.0184s/iter; left time: 18.7039s\n",
      "Epoch: 2 cost time: 1.1409173011779785\n",
      "Epoch: 2, Steps: 124 | Train Loss: 0.5436649 Vali Loss: 0.6268365 Test Loss: 0.4440998\n",
      "Validation loss decreased (0.760479 --> 0.626837).  Saving model ...\n",
      "Updating learning rate to 5e-06\n",
      "\titers: 100, epoch: 3 | loss: 0.4244795\n",
      "\tspeed: 0.0186s/iter; left time: 16.6004s\n",
      "Epoch: 3 cost time: 1.1351253986358643\n",
      "Epoch: 3, Steps: 124 | Train Loss: 0.4774201 Vali Loss: 0.6188768 Test Loss: 0.4139392\n",
      "Validation loss decreased (0.626837 --> 0.618877).  Saving model ...\n",
      "Updating learning rate to 2.5e-06\n",
      "\titers: 100, epoch: 4 | loss: 0.5748489\n",
      "\tspeed: 0.0176s/iter; left time: 13.4961s\n",
      "Epoch: 4 cost time: 1.0969724655151367\n",
      "Epoch: 4, Steps: 124 | Train Loss: 0.4557018 Vali Loss: 0.6048842 Test Loss: 0.4172083\n",
      "Validation loss decreased (0.618877 --> 0.604884).  Saving model ...\n",
      "Updating learning rate to 1.25e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3820329\n",
      "\tspeed: 0.0178s/iter; left time: 11.4870s\n",
      "Epoch: 5 cost time: 1.1121273040771484\n",
      "Epoch: 5, Steps: 124 | Train Loss: 0.4480874 Vali Loss: 0.5941063 Test Loss: 0.4137531\n",
      "Validation loss decreased (0.604884 --> 0.594106).  Saving model ...\n",
      "Updating learning rate to 6.25e-07\n",
      "\titers: 100, epoch: 6 | loss: 0.5471352\n",
      "\tspeed: 0.0182s/iter; left time: 9.4833s\n",
      "Epoch: 6 cost time: 1.1081538200378418\n",
      "Epoch: 6, Steps: 124 | Train Loss: 0.4443671 Vali Loss: 0.5939909 Test Loss: 0.4120630\n",
      "Validation loss decreased (0.594106 --> 0.593991).  Saving model ...\n",
      "Updating learning rate to 3.125e-07\n",
      "\titers: 100, epoch: 7 | loss: 0.4353172\n",
      "\tspeed: 0.0180s/iter; left time: 7.1587s\n",
      "Epoch: 7 cost time: 1.072486162185669\n",
      "Epoch: 7, Steps: 124 | Train Loss: 0.4416147 Vali Loss: 0.5952322 Test Loss: 0.4107797\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-07\n",
      "\titers: 100, epoch: 8 | loss: 0.4027992\n",
      "\tspeed: 0.0172s/iter; left time: 4.7039s\n",
      "Epoch: 8 cost time: 1.1374061107635498\n",
      "Epoch: 8, Steps: 124 | Train Loss: 0.4415122 Vali Loss: 0.5918824 Test Loss: 0.4105946\n",
      "Validation loss decreased (0.593991 --> 0.591882).  Saving model ...\n",
      "Updating learning rate to 7.8125e-08\n",
      "\titers: 100, epoch: 9 | loss: 0.3754034\n",
      "\tspeed: 0.0192s/iter; left time: 2.8549s\n",
      "Epoch: 9 cost time: 1.1602799892425537\n",
      "Epoch: 9, Steps: 124 | Train Loss: 0.4414089 Vali Loss: 0.5962093 Test Loss: 0.4104369\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-08\n",
      "\titers: 100, epoch: 10 | loss: 0.5120544\n",
      "\tspeed: 0.0175s/iter; left time: 0.4363s\n",
      "Epoch: 10 cost time: 1.0945143699645996\n",
      "Epoch: 10, Steps: 124 | Train Loss: 0.4410502 Vali Loss: 0.5904754 Test Loss: 0.4102040\n",
      "Validation loss decreased (0.591882 --> 0.590475).  Saving model ...\n",
      "Updating learning rate to 1.953125e-08\n",
      ">>>>>>>testing : Exchange_336_1day_GLinear_custom_ftM_sl1000_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 1182\n",
      "mse:0.41034525632858276, mae:0.4731200635433197\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : Exchange_336_1day_GLinear_custom_ftM_sl1000_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 3976\n",
      "val 425\n",
      "test 1182\n",
      "\titers: 100, epoch: 1 | loss: 0.5192140\n",
      "\tspeed: 0.0093s/iter; left time: 10.6608s\n",
      "Epoch: 1 cost time: 1.1374468803405762\n",
      "Epoch: 1, Steps: 124 | Train Loss: 0.8528042 Vali Loss: 0.7584096 Test Loss: 0.5534543\n",
      "Validation loss decreased (inf --> 0.758410).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.5031525\n",
      "\tspeed: 0.0185s/iter; left time: 18.7765s\n",
      "Epoch: 2 cost time: 1.112922191619873\n",
      "Epoch: 2, Steps: 124 | Train Loss: 0.5358867 Vali Loss: 0.6288475 Test Loss: 0.4478591\n",
      "Validation loss decreased (0.758410 --> 0.628848).  Saving model ...\n",
      "Updating learning rate to 5e-06\n",
      "\titers: 100, epoch: 3 | loss: 0.4982694\n",
      "\tspeed: 0.0192s/iter; left time: 17.1170s\n",
      "Epoch: 3 cost time: 1.1562371253967285\n",
      "Epoch: 3, Steps: 124 | Train Loss: 0.4738410 Vali Loss: 0.5928460 Test Loss: 0.4242137\n",
      "Validation loss decreased (0.628848 --> 0.592846).  Saving model ...\n",
      "Updating learning rate to 2.5e-06\n",
      "\titers: 100, epoch: 4 | loss: 0.4239506\n",
      "\tspeed: 0.0202s/iter; left time: 15.5357s\n",
      "Epoch: 4 cost time: 1.2018330097198486\n",
      "Epoch: 4, Steps: 124 | Train Loss: 0.4537005 Vali Loss: 0.6041941 Test Loss: 0.4212556\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3976164\n",
      "\tspeed: 0.0179s/iter; left time: 11.5589s\n",
      "Epoch: 5 cost time: 1.0856537818908691\n",
      "Epoch: 5, Steps: 124 | Train Loss: 0.4457970 Vali Loss: 0.5956250 Test Loss: 0.4193083\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-07\n",
      "\titers: 100, epoch: 6 | loss: 0.4326556\n",
      "\tspeed: 0.0175s/iter; left time: 9.1238s\n",
      "Epoch: 6 cost time: 1.0768101215362549\n",
      "Epoch: 6, Steps: 124 | Train Loss: 0.4423924 Vali Loss: 0.5974836 Test Loss: 0.4141032\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : Exchange_336_1day_GLinear_custom_ftM_sl1000_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 1182\n",
      "mse:0.4243442714214325, mae:0.48120537400245667\n",
      "Data: Exchange Rate\n",
      ": Name: Abukar Ali\n",
      "\n",
      "ðŸ“ Saved experiments:\n",
      "exp_basic.py  exp_main.py  exp_stat.py\t__pycache__\n"
     ]
    }
   ],
   "source": [
    "# new Residual Stacked GLinear Model name remains \"GLinear\"\n",
    "%cd /content/drive/MyDrive/MyProject_QMUL_Final/GLinear\n",
    "\n",
    "# Confirming working directory\n",
    "import os\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "\n",
    "# Run training with unique parameter spec for each data set\n",
    "!python run_longExp.py \\\n",
    "  --is_training 1 \\\n",
    "  --model GLinear \\\n",
    "  --data custom \\\n",
    "  --root_path dataset/ \\\n",
    "  --data_path exchange_rate.csv \\\n",
    "  --model_id Exchange_336_1day \\\n",
    "  --features M \\\n",
    "  --target OT \\\n",
    "  --seq_len 1000 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 336 \\\n",
    "  --enc_in 8 \\\n",
    "  --dec_in 8 \\\n",
    "  --c_out 8 \\\n",
    "  --batch_size 32 \\\n",
    "  --learning_rate 0.00001 \\\n",
    "  --use_gpu True \\\n",
    "  --gpu 0\n",
    "\n",
    "# Show saved experiment results\n",
    "print(\"Data: Exchange Rate\")\n",
    "print(\": Name: Abukar Ali\")\n",
    "print(\"\\nðŸ“ Saved experiments:\")\n",
    "!ls ./exp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1748621882593,
     "user": {
      "displayName": "amali amali",
      "userId": "15718090331232743656"
     },
     "user_tz": -60
    },
    "id": "xc_Cwh9qPCca",
    "outputId": "61a825f3-470f-446f-879f-5ca5a7f01b11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/MyProject_QMUL_Final/GLinear\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/MyProject_QMUL_Final/GLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 5617,
     "status": "ok",
     "timestamp": 1748622043412,
     "user": {
      "displayName": "amali amali",
      "userId": "15718090331232743656"
     },
     "user_tz": -60
    },
    "id": "ldV2ETnMN5g6",
    "outputId": "a8a9dc17-6d7a-4f13-f11f-0339e71e1ea3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, train_only=False, model_id='National_Illness_336_96', model='GLinear', data='custom', root_path='dataset/', data_path='national_illness.csv', features='M', target='OT', freq='h', checkpoints='/spo/NewbornTime/tahir098/SVF/data/Extra/checkpoints/', seq_len=36, label_len=48, pred_len=24, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.01, des='test', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : National_Illness_336_96_GLinear_custom_ftM_sl36_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 617\n",
      "val 74\n",
      "test 170\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/drive/MyDrive/MyProject_QMUL_Final/GLinear/run_longExp.py\", line 120, in <module>\n",
      "    exp.train(setting)\n",
      "  File \"/content/drive/MyDrive/MyProject_QMUL_Final/GLinear/exp/exp_main.py\", line 127, in train\n",
      "    for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 708, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1455, in _next_data\n",
      "    return self._process_data(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1505, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_utils.py\", line 733, in reraise\n",
      "    raise exception\n",
      "RuntimeError: Caught RuntimeError in DataLoader worker process 2.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n",
      "    return self.collate_fn(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 398, in default_collate\n",
      "    return collate(batch, collate_fn_map=default_collate_fn_map)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 211, in collate\n",
      "    return [\n",
      "           ^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 212, in <listcomp>\n",
      "    collate(samples, collate_fn_map=collate_fn_map)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 155, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 285, in collate_numpy_array_fn\n",
      "    return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 155, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\", line 272, in collate_tensor_fn\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: stack expects each tensor to be equal size, but got [0, 7] at entry 0 and [72, 7] at entry 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python run_longExp.py \\\n",
    "  --is_training 1 \\\n",
    "  --model GLinear \\\n",
    "  --data custom \\\n",
    "  --root_path dataset/ \\\n",
    "  --data_path national_illness.csv \\\n",
    "  --model_id National_Illness_336_96 \\\n",
    "  --features M \\\n",
    "  --target OT \\\n",
    "  --seq_len 36 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 24 \\\n",
    "  --enc_in 7 \\\n",
    "  --dec_in 7 \\\n",
    "  --c_out 7 \\\n",
    "  --batch_size 32 \\\n",
    "  --learning_rate 0.01 \\\n",
    "  --use_gpu True \\\n",
    "  --gpu 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 20562,
     "status": "ok",
     "timestamp": 1748622559440,
     "user": {
      "displayName": "amali amali",
      "userId": "15718090331232743656"
     },
     "user_tz": -60
    },
    "id": "RRy36Dh6__W9",
    "outputId": "3397b067-95c7-4840-a311-215c023601c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, train_only=False, model_id='National_Illness_24_12', model='GLinear', data='custom', root_path='dataset/', data_path='national_illness.csv', features='M', target='OT', freq='h', checkpoints='/spo/NewbornTime/tahir098/SVF/data/Extra/checkpoints/', seq_len=36, label_len=12, pred_len=36, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=16, patience=3, learning_rate=0.01, des='test', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : National_Illness_24_12_GLinear_custom_ftM_sl36_ll12_pl36_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 605\n",
      "val 62\n",
      "test 158\n",
      "Epoch: 1 cost time: 0.6126396656036377\n",
      "Epoch: 1, Steps: 37 | Train Loss: 1.1710134 Vali Loss: 0.5123178 Test Loss: 3.2557607\n",
      "Validation loss decreased (inf --> 0.512318).  Saving model ...\n",
      "Updating learning rate to 0.01\n",
      "Epoch: 2 cost time: 0.3732411861419678\n",
      "Epoch: 2, Steps: 37 | Train Loss: 0.8606678 Vali Loss: 0.4529865 Test Loss: 2.9846275\n",
      "Validation loss decreased (0.512318 --> 0.452987).  Saving model ...\n",
      "Updating learning rate to 0.005\n",
      "Epoch: 3 cost time: 0.3638267517089844\n",
      "Epoch: 3, Steps: 37 | Train Loss: 0.7767200 Vali Loss: 0.4375670 Test Loss: 2.8470283\n",
      "Validation loss decreased (0.452987 --> 0.437567).  Saving model ...\n",
      "Updating learning rate to 0.0025\n",
      "Epoch: 4 cost time: 0.3720207214355469\n",
      "Epoch: 4, Steps: 37 | Train Loss: 0.7101296 Vali Loss: 0.3935508 Test Loss: 2.5897539\n",
      "Validation loss decreased (0.437567 --> 0.393551).  Saving model ...\n",
      "Updating learning rate to 0.00125\n",
      "Epoch: 5 cost time: 0.36588001251220703\n",
      "Epoch: 5, Steps: 37 | Train Loss: 0.6970013 Vali Loss: 0.3979296 Test Loss: 2.6541629\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.000625\n",
      "Epoch: 6 cost time: 0.36045312881469727\n",
      "Epoch: 6, Steps: 37 | Train Loss: 0.6793206 Vali Loss: 0.3670543 Test Loss: 2.5550845\n",
      "Validation loss decreased (0.393551 --> 0.367054).  Saving model ...\n",
      "Updating learning rate to 0.0003125\n",
      "Epoch: 7 cost time: 0.3503715991973877\n",
      "Epoch: 7, Steps: 37 | Train Loss: 0.6693119 Vali Loss: 0.3737220 Test Loss: 2.5453029\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.00015625\n",
      "Epoch: 8 cost time: 0.369426965713501\n",
      "Epoch: 8, Steps: 37 | Train Loss: 0.6793588 Vali Loss: 0.3643350 Test Loss: 2.5653739\n",
      "Validation loss decreased (0.367054 --> 0.364335).  Saving model ...\n",
      "Updating learning rate to 7.8125e-05\n",
      "Epoch: 9 cost time: 0.35747385025024414\n",
      "Epoch: 9, Steps: 37 | Train Loss: 0.6589687 Vali Loss: 0.3803935 Test Loss: 2.5727050\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-05\n",
      "Epoch: 10 cost time: 0.35249948501586914\n",
      "Epoch: 10, Steps: 37 | Train Loss: 0.6785903 Vali Loss: 0.3570044 Test Loss: 2.5659494\n",
      "Validation loss decreased (0.364335 --> 0.357004).  Saving model ...\n",
      "Updating learning rate to 1.953125e-05\n",
      ">>>>>>>testing : National_Illness_24_12_GLinear_custom_ftM_sl36_ll12_pl36_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 158\n",
      "mse:2.5162572860717773, mae:1.07962167263031\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : National_Illness_24_12_GLinear_custom_ftM_sl36_ll12_pl36_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 605\n",
      "val 62\n",
      "test 158\n",
      "Epoch: 1 cost time: 0.37598228454589844\n",
      "Epoch: 1, Steps: 37 | Train Loss: 1.2060412 Vali Loss: 0.4651242 Test Loss: 3.1330464\n",
      "Validation loss decreased (inf --> 0.465124).  Saving model ...\n",
      "Updating learning rate to 0.01\n",
      "Epoch: 2 cost time: 0.3679342269897461\n",
      "Epoch: 2, Steps: 37 | Train Loss: 0.8521171 Vali Loss: 0.5624695 Test Loss: 3.2304733\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.005\n",
      "Epoch: 3 cost time: 0.364910364151001\n",
      "Epoch: 3, Steps: 37 | Train Loss: 0.7816567 Vali Loss: 0.4093392 Test Loss: 3.2674251\n",
      "Validation loss decreased (0.465124 --> 0.409339).  Saving model ...\n",
      "Updating learning rate to 0.0025\n",
      "Epoch: 4 cost time: 0.3657948970794678\n",
      "Epoch: 4, Steps: 37 | Train Loss: 0.7304019 Vali Loss: 0.4265406 Test Loss: 2.8115122\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.00125\n",
      "Epoch: 5 cost time: 0.35947608947753906\n",
      "Epoch: 5, Steps: 37 | Train Loss: 0.7188781 Vali Loss: 0.3937706 Test Loss: 2.8637571\n",
      "Validation loss decreased (0.409339 --> 0.393771).  Saving model ...\n",
      "Updating learning rate to 0.000625\n",
      "Epoch: 6 cost time: 0.356259822845459\n",
      "Epoch: 6, Steps: 37 | Train Loss: 0.6947672 Vali Loss: 0.3727866 Test Loss: 2.6794763\n",
      "Validation loss decreased (0.393771 --> 0.372787).  Saving model ...\n",
      "Updating learning rate to 0.0003125\n",
      "Epoch: 7 cost time: 0.359774112701416\n",
      "Epoch: 7, Steps: 37 | Train Loss: 0.6982789 Vali Loss: 0.3974091 Test Loss: 2.6868718\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.00015625\n",
      "Epoch: 8 cost time: 0.3676109313964844\n",
      "Epoch: 8, Steps: 37 | Train Loss: 0.6928666 Vali Loss: 0.3772757 Test Loss: 2.6723962\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-05\n",
      "Epoch: 9 cost time: 0.3635571002960205\n",
      "Epoch: 9, Steps: 37 | Train Loss: 0.6851334 Vali Loss: 0.3933274 Test Loss: 2.6664357\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : National_Illness_24_12_GLinear_custom_ftM_sl36_ll12_pl36_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 158\n",
      "mse:2.6288540363311768, mae:1.0959285497665405\n"
     ]
    }
   ],
   "source": [
    "!python run_longExp.py \\\n",
    "  --is_training 1 \\\n",
    "  --model GLinear \\\n",
    "  --data custom \\\n",
    "  --root_path dataset/ \\\n",
    "  --data_path national_illness.csv \\\n",
    "  --model_id National_Illness_24_12 \\\n",
    "  --features M \\\n",
    "  --target OT \\\n",
    "  --seq_len 36 \\\n",
    "  --label_len 12 \\\n",
    "  --pred_len 36 \\\n",
    "  --enc_in 7 \\\n",
    "  --dec_in 7 \\\n",
    "  --c_out 7 \\\n",
    "  --batch_size 16 \\\n",
    "  --learning_rate 0.01 \\\n",
    "  --use_gpu True \\\n",
    "  --gpu 0\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPjREHcW1X7yDoqzMsmrJfS",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
